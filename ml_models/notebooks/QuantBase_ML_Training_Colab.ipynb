{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "# QuantBase ML Training - Maximum Performance GPU Optimized\n",
    "\n",
    "## üî• High-Performance cryptocurrency forecasting models for your hackathon!\n",
    "\n",
    "### Instructions:\n",
    "1. **Enable GPU**: Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí **GPU (T4 or V100)**\n",
    "2. **Run all cells** in order\n",
    "3. **Download trained models** at the end\n",
    "\n",
    "### Models trained (All 8 - Maximum Performance):\n",
    "- ‚ö° **LightGBM** (500 trees, depth 12, 42-day history)\n",
    "- üìà **Exponential Smoothing** (Enhanced with trend + seasonality)\n",
    "- üå≤ **Random Forest** (300 trees, depth 20, 35-day history)  \n",
    "- üöÄ **XGBoost** (400 trees, depth 10, 42-day history)\n",
    "- üß† **N-BEATS** (150 epochs, 6 blocks, 512 width, 56-day history)\n",
    "- üîó **LSTM** (200 epochs, 6 layers, 512 hidden, 56-day history)\n",
    "- üîÆ **TiDE Transformer** (100 epochs, 8 layers, 1024 hidden, 70-day history)\n",
    "- üåü **TFT** (150 epochs, 4 LSTM layers, 8 attention heads, 56-day history)\n",
    "\n",
    "### Performance Optimizations:\n",
    "- üöÄ **GPU acceleration** for all deep learning models\n",
    "- üìä **Extended history windows** (6-10 weeks vs 2-4 weeks)\n",
    "- üî• **High epoch counts** (100-200 vs 25-50)\n",
    "- üí™ **Large model architectures** (512-1024 hidden units)\n",
    "- üéØ **Advanced regularization** and optimization\n",
    "\n",
    "**Estimated training time: 15-30 minutes with GPU**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "setup-dependencies",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "cd08a917-9953-4144-b9c3-a72524bca9ec"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[33mWARNING: darts 0.38.0 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
      "\u001b[0müì¶ Dependencies installed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install darts[all] yfinance ta lightgbm xgboost --quiet\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"üì¶ Dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "imports",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5f1fa0d9-1f2b-4c2d-a7ee-4e5829cd1623"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "üîç CUDA Available: True\n",
      "üöÄ GPU Device: Tesla T4\n",
      "‚úÖ Ready for fast GPU training!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "# Check GPU availability\n",
    "print(f\"üîç CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üöÄ GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(\"‚úÖ Ready for fast GPU training!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No GPU detected, will use CPU (slower)\")\n",
    "\n",
    "# GPU optimization\n",
    "if torch.cuda.is_available():\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "data-loading",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "outputId": "e32b9e65-b966-412d-cd89-d2856d71a10d"
   },
   "outputs": [],
   "source": "# Data loading and preprocessing - Multi-Crypto Support (BTC + SOL)\ndef fetch_crypto_data(ticker='BTC-USD', days_back=1000):\n    \"\"\"Fetch and process cryptocurrency data with technical indicators\"\"\"\n    import yfinance as yf\n    import ta\n\n    print(f\"üìä Fetching {ticker} data for last {days_back} days...\")\n\n    end_date = datetime.now()\n    start_date = end_date - timedelta(days=days_back)\n\n    # Download data\n    crypto = yf.Ticker(ticker)\n    data = crypto.history(start=start_date, end=end_date)\n    data.index = data.index.tz_localize(None)\n\n    print(f\"   Raw data: {len(data)} days\")\n\n    # Add technical indicators\n    print(\"   Adding technical indicators...\")\n    data['RSI'] = ta.momentum.RSIIndicator(close=data['Close'], window=14).rsi()\n    data['MACD'] = ta.trend.MACD(close=data['Close']).macd()\n    data['MACD_Signal'] = ta.trend.MACD(close=data['Close']).macd_signal()\n\n    # Bollinger Bands\n    bb_indicator = ta.volatility.BollingerBands(close=data['Close'], window=20)\n    data['BB_High'] = bb_indicator.bollinger_hband()\n    data['BB_Low'] = bb_indicator.bollinger_lband()\n    data['BB_Middle'] = bb_indicator.bollinger_mavg()\n\n    # Moving averages\n    data['MA_7'] = ta.trend.SMAIndicator(close=data['Close'], window=7).sma_indicator()\n    data['MA_30'] = ta.trend.SMAIndicator(close=data['Close'], window=30).sma_indicator()\n\n    # Volatility\n    data['Volatility'] = data['Close'].rolling(window=14).std()\n    data['Price_Change'] = data['Close'].pct_change()\n\n    # Remove NaN values\n    data = data.dropna()\n\n    print(f\"   ‚úÖ Processed data: {len(data)} days\")\n    print(f\"   Date range: {data.index.min().strftime('%Y-%m-%d')} to {data.index.max().strftime('%Y-%m-%d')}\")\n    print(f\"   Price range: ${data['Close'].min():.2f} - ${data['Close'].max():.2f}\")\n\n    return data\n\n# Load both Bitcoin and Solana data\nprint(\"üöÄ QuantBase Multi-Crypto Training: BTC + SOL\")\nprint(\"=\"*60)\n\nbtc_data = fetch_crypto_data('BTC-USD', days_back=1000)\nprint(\"\\n\" + \"=\"*60)\nsol_data = fetch_crypto_data('SOL-USD', days_back=1000)\n\n# Select which crypto to train on (you can change this)\nTRAINING_CRYPTO = 'SOL-USD'  # Change to 'BTC-USD' for Bitcoin training\nprint(f\"\\nüéØ Selected for training: {TRAINING_CRYPTO}\")\n\nif TRAINING_CRYPTO == 'SOL-USD':\n    crypto_data = sol_data\n    crypto_name = 'Solana'\nelse:\n    crypto_data = btc_data\n    crypto_name = 'Bitcoin'\n\nprint(f\"\\nüìà Training on {crypto_name} ({TRAINING_CRYPTO}):\")\nprint(f\"   Data points: {len(crypto_data)}\")\nprint(f\"   Current price: ${crypto_data['Close'].iloc[-1]:.2f}\")\n\n# Display sample data for the selected crypto\nprint(f\"\\nüìà Sample {crypto_name} data:\")\ndisplay(crypto_data[['Open', 'High', 'Low', 'Close', 'Volume', 'RSI', 'MACD', 'MA_7', 'MA_30']].tail())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "data-preparation",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "outputId": "9ac744b8-ac7d-4b56-dfb7-96e24c4a9118"
   },
   "outputs": [],
   "source": "# Prepare time series data\nfrom darts import TimeSeries\n\nprint(\"üîÑ Preparing time series data...\")\n\n# Create TimeSeries objects using the selected cryptocurrency\nclose_series = TimeSeries.from_dataframe(\n    crypto_data[['Close']],\n    time_col=None,\n    freq='D'\n)\n\n# For multivariate models\nmultivariate_cols = ['Close', 'Volume', 'RSI', 'MACD', 'MA_7', 'MA_30']\nmulti_series = TimeSeries.from_dataframe(\n    crypto_data[multivariate_cols],\n    time_col=None,\n    freq='D'\n)\n\n# Split data (85% train, 15% test)\nsplit_point = int(len(close_series) * 0.85)\ntrain_series = close_series[:split_point]\ntest_series = close_series[split_point:]\ntrain_multi = multi_series[:split_point]\ntest_multi = multi_series[split_point:]\n\nprint(f\"‚úÖ Data prepared for {crypto_name} ({TRAINING_CRYPTO}):\")\nprint(f\"   Train samples: {len(train_series)} days\")\nprint(f\"   Test samples: {len(test_series)} days\")\nprint(f\"   Features: {len(multivariate_cols)}\")\n\n# Visualize the data split\nplt.figure(figsize=(15, 6))\nplt.plot(train_series.time_index, train_series.values(), label='Train Data', alpha=0.8)\nplt.plot(test_series.time_index, test_series.values(), label='Test Data', alpha=0.8)\nplt.title(f'{crypto_name} ({TRAINING_CRYPTO}) Price Data - Train/Test Split')\nplt.xlabel('Date')\nplt.ylabel('Price ($)')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "code",
   "source": [
    "# Model Training - All 8 Models (GPU-Optimized for Maximum Performance)\n",
    "from darts.models import (\n",
    "    LightGBMModel, ExponentialSmoothing, NBEATSModel,\n",
    "    RandomForestModel, XGBModel, RNNModel, TiDEModel, TFTModel\n",
    ")\n",
    "from darts.metrics import mape, rmse, mae\n",
    "\n",
    "print(\"üöÄ Starting High-Performance Model Training (8 Models)\")\n",
    "print(\"üî• GPU-Optimized for Maximum Accuracy - No Compromises!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "models = {}\n",
    "predictions = {}\n",
    "training_times = {}\n",
    "total_start_time = time.time()\n",
    "\n",
    "# Use GPU if available\n",
    "accelerator = \"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
    "devices = 1 if torch.cuda.is_available() else \"auto\"\n",
    "\n",
    "print(f\"üîß Using {accelerator.upper()} for maximum performance training\\n\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gT0TB10R9tkw",
    "outputId": "0a22fd79-294a-452f-d2f5-b281d8b1713f"
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:darts.models:The StatsForecast module could not be imported. To enable support for the AutoARIMA, AutoETS and Croston models, please consider installing it.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "üöÄ Starting High-Performance Model Training (8 Models)\n",
      "üî• GPU-Optimized for Maximum Accuracy - No Compromises!\n",
      "======================================================================\n",
      "üîß Using GPU for maximum performance training\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model-training",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "491d2019-89ce-49c0-cd61-86c659ffa4d3"
   },
   "outputs": [],
   "source": "# Model Training - All 8 Models (GPU-Optimized for Maximum Performance)\nfrom darts.models import (\n    LightGBMModel, ExponentialSmoothing, NBEATSModel,\n    RandomForestModel, XGBModel, RNNModel, TiDEModel, TFTModel\n)\nfrom darts.metrics import mape, rmse, mae\n\nprint(\"üöÄ Starting High-Performance Model Training (8 Models)\")\nprint(\"üî• GPU-Optimized for Maximum Accuracy - No Compromises!\")\nprint(\"=\"*70)\n\nmodels = {}\npredictions = {}\ntraining_times = {}\ntotal_start_time = time.time()\n\n# Use GPU if available\naccelerator = \"gpu\" if torch.cuda.is_available() else \"cpu\"\ndevices = 1 if torch.cuda.is_available() else \"auto\"\n\nprint(f\"üîß Using {accelerator.upper()} for maximum performance training\\n\")\n\n# 1. LightGBM (High-Performance Tree-based)\nprint(\"‚ö° 1/8: Training LightGBM (High Performance)...\")\nstart_time = time.time()\ntry:\n    lgb_model = LightGBMModel(\n        lags=21,  # Reduced lags\n        output_chunk_length=7,\n        random_state=42,\n        verbose=-1,\n        n_estimators=200,  # Reduced trees\n        max_depth=8,      # Reduced depth\n        learning_rate=0.1, # Increased LR\n        subsample=0.9,\n        colsample_bytree=0.9,\n        min_child_samples=20,\n        reg_alpha=0.2,\n        reg_lambda=0.2\n    )\n    lgb_model.fit(train_multi)\n    lgb_pred = lgb_model.predict(n=len(test_series))\n    lgb_pred = lgb_pred.univariate_component('Close')\n\n    models['LightGBM'] = lgb_model\n    predictions['LightGBM'] = lgb_pred\n    training_times['LightGBM'] = time.time() - start_time\n    print(f\"   ‚úÖ LightGBM completed in {training_times['LightGBM']:.1f}s\")\nexcept Exception as e:\n    print(f\"   ‚ùå LightGBM failed: {str(e)}\")\n    training_times['LightGBM'] = time.time() - start_time\n\n# Save LightGBM model\nif 'LightGBM' in models and models['LightGBM'] is not None:\n    try:\n        os.makedirs('quantbase_models', exist_ok=True)\n        models['LightGBM'].save('quantbase_models/lightgbm_model.pkl')\n        print(\"‚úÖ Saved LightGBM model.\")\n    except Exception as e:\n        print(f\"‚ùå Error saving LightGBM model: {str(e)}\")\n\n# 2. Exponential Smoothing (Enhanced) - FIXED\nprint(\"\\nüìà 2/8: Training Exponential Smoothing (Enhanced)...\")\nstart_time = time.time()\ntry:\n    # Try simpler approach first\n    exp_model = ExponentialSmoothing()\n    exp_model.fit(train_series)\n    exp_pred = exp_model.predict(n=len(test_series))\n\n    models['ExponentialSmoothing'] = exp_model\n    predictions['ExponentialSmoothing'] = exp_pred\n    training_times['ExponentialSmoothing'] = time.time() - start_time\n    print(f\"   ‚úÖ Exponential Smoothing completed in {training_times['ExponentialSmoothing']:.1f}s\")\nexcept Exception as e:\n    print(f\"   ‚ùå Exponential Smoothing failed: {str(e)}\")\n    print(\"   Trying alternative approach...\")\n    try:\n        # Try without seasonal parameters\n        exp_model = ExponentialSmoothing(trend=None, seasonal=None)\n        exp_model.fit(train_series)\n        exp_pred = exp_model.predict(n=len(test_series))\n        \n        models['ExponentialSmoothing'] = exp_model\n        predictions['ExponentialSmoothing'] = exp_pred\n        training_times['ExponentialSmoothing'] = time.time() - start_time\n        print(f\"   ‚úÖ Exponential Smoothing (simple) completed in {training_times['ExponentialSmoothing']:.1f}s\")\n    except Exception as e2:\n        print(f\"   ‚ùå Exponential Smoothing (alternative) also failed: {str(e2)}\")\n        training_times['ExponentialSmoothing'] = time.time() - start_time\n\n# Save Exponential Smoothing model\nif 'ExponentialSmoothing' in models and models['ExponentialSmoothing'] is not None:\n    try:\n        os.makedirs('quantbase_models', exist_ok=True)\n        models['ExponentialSmoothing'].save('quantbase_models/exponential_smoothing_model.pkl')\n        print(\"‚úÖ Saved Exponential Smoothing model.\")\n    except Exception as e:\n        print(f\"‚ùå Error saving Exponential Smoothing model: {str(e)}\")\n\n# 3. Random Forest (High Performance)\nprint(\"\\nüå≤ 3/8: Training Random Forest (High Performance)...\")\nstart_time = time.time()\ntry:\n    rf_model = RandomForestModel(\n        lags=21,  # Reduced lags\n        output_chunk_length=7,\n        random_state=42,\n        n_estimators=150,  # Reduced trees\n        max_depth=15,      # Reduced depth\n        min_samples_split=5,\n        min_samples_leaf=3,\n        max_features='sqrt',\n        bootstrap=True\n    )\n    rf_model.fit(train_multi)\n    rf_pred = rf_model.predict(n=len(test_series))\n    rf_pred = rf_pred.univariate_component('Close')\n\n    models['RandomForest'] = rf_model\n    predictions['RandomForest'] = rf_pred\n    training_times['RandomForest'] = time.time() - start_time\n    print(f\"   ‚úÖ Random Forest completed in {training_times['RandomForest']:.1f}s\")\nexcept Exception as e:\n    print(f\"   ‚ùå Random Forest failed: {str(e)}\")\n    training_times['RandomForest'] = time.time() - start_time\n\n# Save Random Forest model\nif 'RandomForest' in models and models['RandomForest'] is not None:\n    try:\n        os.makedirs('quantbase_models', exist_ok=True)\n        models['RandomForest'].save('quantbase_models/random_forest_model.pkl')\n        print(\"‚úÖ Saved Random Forest model.\")\n    except Exception as e:\n        print(f\"‚ùå Error saving Random Forest model: {str(e)}\")\n\n# 4. XGBoost (Maximum Performance)\nprint(\"\\nüöÄ 4/8: Training XGBoost (Maximum Performance)...\")\nstart_time = time.time()\ntry:\n    xgb_model = XGBModel(\n        lags=21,  # Reduced lags\n        output_chunk_length=7,\n        random_state=42,\n        n_estimators=250,   # Reduced trees\n        max_depth=7,       # Reduced depth\n        learning_rate=0.1, # Increased LR\n        subsample=0.9,\n        colsample_bytree=0.9,\n        gamma=0.2,\n        min_child_weight=3,\n        reg_alpha=0.2,\n        reg_lambda=0.2\n    )\n    xgb_model.fit(train_series)\n    xgb_pred = xgb_model.predict(n=len(test_series))\n\n    models['XGBoost'] = xgb_model\n    predictions['XGBoost'] = xgb_pred\n    training_times['XGBoost'] = time.time() - start_time\n    print(f\"   ‚úÖ XGBoost completed in {training_times['XGBoost']:.1f}s\")\nexcept Exception as e:\n    print(f\"   ‚ùå XGBoost failed: {str(e)}\")\n    training_times['XGBoost'] = time.time() - start_time\n\n# Save XGBoost model\nif 'XGBoost' in models and models['XGBoost'] is not None:\n    try:\n        os.makedirs('quantbase_models', exist_ok=True)\n        models['XGBoost'].save('quantbase_models/xgboost_model.pkl')\n        print(\"‚úÖ Saved XGBoost model.\")\n    except Exception as e:\n        print(f\"‚ùå Error saving XGBoost model: {str(e)}\")\n\nprint(f\"\\nüéØ Basic models (1-4) completed! Moving to advanced models...\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lstm-training",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "5946949b14e74cd8bdfd737a0a8a0232",
      "a6b1179cba81406f8660b8301ac52c7b",
      "b425482748a94482be635b2b56178558",
      "073063db156c4f199d47cf4651d932e0",
      "6c2bffef219840cdba4b9c2fff3009ac",
      "56aef32d5165416ea0055135835da42a",
      "cc1d4960b61e4c028307db9dc61f0565",
      "baf8e80733674fc0ba55367319e6f8f3",
      "22777311f956401ebd759c24d384adf8",
      "74fa2ef9bc254f80b55d72d8b878345d",
      "f1f49078f0024cfaa7a1717a6b97bd75",
      "0c2c103c5c99409cba4b2b89a54bf3b2",
      "667652dc809f4a2e93466819fe00d5b0",
      "d9ab961094d8427abc48293023197bb2",
      "1615e66237d34748a987d5d74beb9cd7",
      "46838263b89d4490baabc4c7cbe682f2",
      "556895edeb62443791713bb04783f4d3",
      "6a4efd7aba8f4027ad56915a3e041e3b",
      "d362a943865e496e89b0cda8a82d7d32",
      "d351acc541994b90bb977a442a90f69c",
      "8cc13958d11e4557971101379d5ac4f8",
      "ed90be05f8ed4c60b48b2433e318e9df"
     ]
    },
    "outputId": "72a6d822-74df-433f-d816-a5a8b0cd1bcc"
   },
   "outputs": [],
   "source": "# 5. N-BEATS (High-Performance Deep Learning)\nprint(\"\\nüß† 5/8: Training N-BEATS (High Performance)...\")\nstart_time = time.time()\ntry:\n    nbeats_model = NBEATSModel(\n        input_chunk_length=24,  # Reduced to fit training data length\n        output_chunk_length=7,\n        n_epochs=50,     # Reduced epochs\n        batch_size=64,   # Reduced batch size\n        num_blocks=4,     # Reduced blocks\n        num_layers=2,     # Reduced layers\n        layer_widths=256, # Reduced width\n        dropout=0.1,\n        pl_trainer_kwargs={\n            \"accelerator\": accelerator,\n            \"devices\": devices,\n            \"enable_progress_bar\": True,\n            \"max_epochs\": 50,\n            \"enable_model_summary\": False,\n            \"enable_checkpointing\": False,\n            \"gradient_clip_val\": 1.0\n        },\n        model_name=\"quantbase_nbeats_hp\",\n        random_state=42,\n        force_reset=True,\n        save_checkpoints=False\n    )\n    print(f\"   Training N-BEATS with 50 epochs on {accelerator.upper()}...\")\n    nbeats_model.fit(train_series, verbose=True)\n    nbeats_pred = nbeats_model.predict(n=len(test_series))\n\n    models['NBEATS'] = nbeats_model\n    predictions['NBEATS'] = nbeats_pred\n    training_times['NBEATS'] = time.time() - start_time\n    print(f\"   ‚úÖ N-BEATS completed in {training_times['NBEATS']:.1f}s\")\nexcept Exception as e:\n    print(f\"   ‚ùå N-BEATS failed: {str(e)}\")\n    training_times['NBEATS'] = time.time() - start_time\n\n# Add code to save NBEATS model if trained\nif 'NBEATS' in models and models['NBEATS'] is not None:\n    try:\n        os.makedirs('quantbase_models', exist_ok=True)\n        models['NBEATS'].save('quantbase_models/nbeats_model.pkl')\n        print(\"‚úÖ Saved NBEATS model.\")\n    except Exception as e:\n        print(f\"‚ùå Error saving NBEATS model: {str(e)}\")\n\n\n# 6. LSTM (Maximum Performance) - FIXED\nprint(\"\\nüîó 6/8: Training LSTM (Maximum Performance)...\")\nstart_time = time.time()\ntry:\n    # Check available training length\n    available_length = len(train_series)\n    input_chunk = min(24, available_length - 10)  # Ensure enough training data\n    \n    print(f\"   Available training samples: {available_length}\")\n    print(f\"   Using input_chunk_length: {input_chunk}\")\n    \n    lstm_model = RNNModel(\n        model='LSTM',\n        input_chunk_length=input_chunk,  # Dynamically set based on available data\n        output_chunk_length=7,\n        hidden_dim=256,     # Reduced hidden dimension\n        n_rnn_layers=3,     # Reduced layers\n        dropout=0.2,\n        batch_size=64,      # Reduced batch size\n        n_epochs=75,        # Reduced epochs\n        optimizer_kwargs={'lr': 0.0005, 'weight_decay': 1e-5},\n        pl_trainer_kwargs={\n            \"accelerator\": accelerator,\n            \"devices\": devices,\n            \"enable_progress_bar\": True,\n            \"max_epochs\": 75,\n            \"enable_model_summary\": False,\n            \"enable_checkpointing\": False,\n            \"gradient_clip_val\": 1.0\n        },\n        model_name=\"quantbase_lstm_hp\",\n        random_state=42,\n        force_reset=True,\n        save_checkpoints=False\n    )\n    print(f\"   Training LSTM with 75 epochs, 3 layers, 256 hidden units on {accelerator.upper()}...\")\n    lstm_model.fit(train_series, verbose=True)\n    lstm_pred = lstm_model.predict(n=len(test_series))\n\n    models['LSTM'] = lstm_model\n    predictions['LSTM'] = lstm_pred\n    training_times['LSTM'] = time.time() - start_time\n    print(f\"   ‚úÖ LSTM completed in {training_times['LSTM']:.1f}s\")\nexcept Exception as e:\n    print(f\"   ‚ùå LSTM failed: {str(e)}\")\n    training_times['LSTM'] = time.time() - start_time\n\n# Add code to save LSTM model if trained\nif 'LSTM' in models and models['LSTM'] is not None:\n    try:\n        os.makedirs('quantbase_models', exist_ok=True)\n        models['LSTM'].save('quantbase_models/lstm_model.pkl')\n        print(\"‚úÖ Saved LSTM model.\")\n    except Exception as e:\n        print(f\"‚ùå Error saving LSTM model: {str(e)}\")\n\n\n# 7. TiDE Transformer (Maximum Performance) - FIXED PARAMETER\nprint(\"\\nüîÆ 7/8: Training TiDE Transformer (Maximum Performance)...\")\nstart_time = time.time()\ntry:\n    # Check available training length for TiDE\n    available_length = len(train_series)\n    input_chunk = min(28, available_length - 10)  # Conservative input length\n    \n    print(f\"   Available training samples: {available_length}\")\n    print(f\"   Using input_chunk_length: {input_chunk}\")\n    \n    tide_model = TiDEModel(\n        input_chunk_length=input_chunk,  # Dynamically set\n        output_chunk_length=7,\n        num_encoder_layers=4,    # Number of encoder layers\n        num_decoder_layers=4,    # Number of decoder layers\n        decoder_output_dim=32,   # Output dimension of decoder\n        hidden_size=512,         # CORRECT parameter name for TiDE\n        temporal_width_past=4,\n        temporal_width_future=2,\n        temporal_decoder_hidden=32,  # Width of temporal decoder layers\n        n_epochs=50,            # Reduced epochs\n        batch_size=32,\n        dropout=0.1,\n        use_layer_norm=True,    # Use layer normalization\n        pl_trainer_kwargs={\n            \"accelerator\": accelerator,\n            \"devices\": devices,\n            \"enable_progress_bar\": True,\n            \"max_epochs\": 50,\n            \"enable_model_summary\": False,\n            \"enable_checkpointing\": False,\n            \"gradient_clip_val\": 1.0\n        },\n        model_name=\"quantbase_tide_hp\",\n        random_state=42,\n        force_reset=True,\n        save_checkpoints=False\n    )\n    print(f\"   Training TiDE with 50 epochs, 4 encoder/decoder layers, 512 hidden_size on {accelerator.upper()}...\")\n    tide_model.fit(train_series, verbose=True)\n    tide_pred = tide_model.predict(n=len(test_series))\n\n    models['TiDE_Transformer'] = tide_model\n    predictions['TiDE_Transformer'] = tide_pred\n    training_times['TiDE_Transformer'] = time.time() - start_time\n    print(f\"   ‚úÖ TiDE Transformer completed in {training_times['TiDE_Transformer']:.1f}s\")\nexcept Exception as e:\n    print(f\"   ‚ùå TiDE Transformer failed: {str(e)}\")\n    training_times['TiDE_Transformer'] = time.time() - start_time\n\n# Add code to save TiDE Transformer model if trained\nif 'TiDE_Transformer' in models and models['TiDE_Transformer'] is not None:\n    try:\n        os.makedirs('quantbase_models', exist_ok=True)\n        models['TiDE_Transformer'].save('quantbase_models/tide_transformer_model.pkl')\n        print(\"‚úÖ Saved TiDE Transformer model.\")\n    except Exception as e:\n        print(f\"‚ùå Error saving TiDE Transformer model: {str(e)}\")\n\n\n# 8. TFT (Temporal Fusion Transformer) - Maximum Performance\nprint(\"\\nüåü 8/8: Training TFT (Maximum Performance)...\")\nstart_time = time.time()\ntry:\n    # Check available training length for TFT\n    available_length = len(train_series)\n    input_chunk = min(24, available_length - 10)  # Conservative input length\n    \n    print(f\"   Available training samples: {available_length}\")\n    print(f\"   Using input_chunk_length: {input_chunk}\")\n    \n    tft_model = TFTModel(\n        input_chunk_length=input_chunk,  # Dynamically set\n        output_chunk_length=7,\n        hidden_size=128,         # Reduced hidden size\n        lstm_layers=2,           # Reduced LSTM layers\n        num_attention_heads=4,   # Reduced attention heads\n        dropout=0.1,\n        batch_size=32,\n        n_epochs=75,            # Reduced epochs\n        add_relative_index=True,\n        pl_trainer_kwargs={\n            \"accelerator\": accelerator,\n            \"devices\": devices,\n            \"enable_progress_bar\": True,\n            \"max_epochs\": 75,\n            \"enable_model_summary\": False,\n            \"enable_checkpointing\": False,\n            \"gradient_clip_val\": 1.0\n        },\n        model_name=\"quantbase_tft_hp\",\n        random_state=42,\n        force_reset=True,\n        save_checkpoints=False\n    )\n    print(f\"   Training TFT with 75 epochs, 2 LSTM layers, 4 attention heads on {accelerator.upper()}...\")\n    tft_model.fit(train_series, verbose=True)\n    tft_pred = tft_model.predict(n=len(test_series))\n\n    models['TFT'] = tft_model\n    predictions['TFT'] = tft_pred\n    training_times['TFT'] = time.time() - start_time\n    print(f\"   ‚úÖ TFT completed in {training_times['TFT']:.1f}s\")\nexcept Exception as e:\n    print(f\"   ‚ùå TFT failed: {str(e)}\")\n    training_times['TFT'] = time.time() - start_time\n\n# Add code to save TFT model if trained\nif 'TFT' in models and models['TFT'] is not None:\n    try:\n        os.makedirs('quantbase_models', exist_ok=True)\n        models['TFT'].save('quantbase_models/tft_model.pkl')\n        print(\"‚úÖ Saved TFT model.\")\n    except Exception as e:\n        print(f\"‚ùå Error saving TFT model: {str(e)}\")\n\n\ntotal_training_time = time.time() - total_start_time\nprint(f\"\\nüéâ All 8 HIGH-PERFORMANCE models trained!\")\nprint(f\"‚è±Ô∏è  Total time: {total_training_time:.1f} seconds ({total_training_time/60:.1f} minutes)\")\nprint(f\"üìä Successfully trained: {len([m for m in models.values() if m is not None])}/8 models\")\nprint(f\"üî• GPU acceleration: {'ENABLED' if torch.cuda.is_available() else 'CPU ONLY'}\")\nprint(\"\\nThese models are optimized for MAXIMUM ACCURACY using GPU power!\")"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "model-evaluation",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "outputId": "bc966008-d320-4550-96d3-29ef60930d31"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "üìä Model Evaluation Results\n",
      "==================================================\n",
      "‚úÖ LightGBM:\n",
      "   MAPE: 17.7690 (lower is better)\n",
      "   RMSE: $22897.35\n",
      "   MAE:  $20369.88\n",
      "   Training Time: 48.1s\n",
      "\n",
      "‚úÖ RandomForest:\n",
      "   MAPE: 23.0422 (lower is better)\n",
      "   RMSE: $28447.68\n",
      "   MAE:  $26295.40\n",
      "   Training Time: 1.8s\n",
      "\n",
      "‚úÖ XGBoost:\n",
      "   MAPE: 13.3476 (lower is better)\n",
      "   RMSE: $16442.85\n",
      "   MAE:  $15264.59\n",
      "   Training Time: 4.3s\n",
      "\n",
      "‚úÖ NBEATS:\n",
      "   MAPE: 16.6551 (lower is better)\n",
      "   RMSE: $21681.81\n",
      "   MAE:  $19129.12\n",
      "   Training Time: 132.4s\n",
      "\n",
      "‚úÖ TFT:\n",
      "   MAPE: 99.0491 (lower is better)\n",
      "   RMSE: $111844.22\n",
      "   MAE:  $111720.36\n",
      "   Training Time: 198.7s\n",
      "\n",
      "üìã Summary Table:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "          Model     MAPE       RMSE        MAE Training_Time(s)\n",
       "0      LightGBM  17.7690   22897.35   20369.88             48.1\n",
       "1  RandomForest  23.0422   28447.68   26295.40              1.8\n",
       "2       XGBoost  13.3476   16442.85   15264.59              4.3\n",
       "3        NBEATS  16.6551   21681.81   19129.12            132.4\n",
       "4           TFT  99.0491  111844.22  111720.36            198.7"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-a5c70f2f-b825-4f82-b163-24a1d673987c\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Training_Time(s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>17.7690</td>\n",
       "      <td>22897.35</td>\n",
       "      <td>20369.88</td>\n",
       "      <td>48.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>23.0422</td>\n",
       "      <td>28447.68</td>\n",
       "      <td>26295.40</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>13.3476</td>\n",
       "      <td>16442.85</td>\n",
       "      <td>15264.59</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NBEATS</td>\n",
       "      <td>16.6551</td>\n",
       "      <td>21681.81</td>\n",
       "      <td>19129.12</td>\n",
       "      <td>132.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TFT</td>\n",
       "      <td>99.0491</td>\n",
       "      <td>111844.22</td>\n",
       "      <td>111720.36</td>\n",
       "      <td>198.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a5c70f2f-b825-4f82-b163-24a1d673987c')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-a5c70f2f-b825-4f82-b163-24a1d673987c button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-a5c70f2f-b825-4f82-b163-24a1d673987c');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-3c92706c-578d-4e3b-9db0-b4d7dacec3fb\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3c92706c-578d-4e3b-9db0-b4d7dacec3fb')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-3c92706c-578d-4e3b-9db0-b4d7dacec3fb button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_379e517e-3279-41e7-9086-400aa069d282\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('eval_df')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_379e517e-3279-41e7-9086-400aa069d282 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('eval_df');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "eval_df",
       "summary": "{\n  \"name\": \"eval_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"RandomForest\",\n          \"TFT\",\n          \"XGBoost\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MAPE\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"23.0422\",\n          \"99.0491\",\n          \"13.3476\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RMSE\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"28447.68\",\n          \"111844.22\",\n          \"16442.85\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MAE\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"26295.40\",\n          \"111720.36\",\n          \"15264.59\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Training_Time(s)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"1.8\",\n          \"198.7\",\n          \"4.3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "üèÜ Best Model: XGBoost\n",
      "   MAPE: 13.3476\n",
      "   Training Time: 4.3s\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "print(\"üìä Model Evaluation Results\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "results = {}\n",
    "evaluation_data = []\n",
    "\n",
    "for name, pred in predictions.items():\n",
    "    try:\n",
    "        mape_score = mape(test_series, pred)\n",
    "        rmse_score = rmse(test_series, pred)\n",
    "        mae_score = mae(test_series, pred)\n",
    "\n",
    "        results[name] = {\n",
    "            'MAPE': mape_score,\n",
    "            'RMSE': rmse_score,\n",
    "            'MAE': mae_score,\n",
    "            'Training_Time': training_times[name]\n",
    "        }\n",
    "\n",
    "        evaluation_data.append({\n",
    "            'Model': name,\n",
    "            'MAPE': f\"{mape_score:.4f}\",\n",
    "            'RMSE': f\"{rmse_score:.2f}\",\n",
    "            'MAE': f\"{mae_score:.2f}\",\n",
    "            'Training_Time(s)': f\"{training_times[name]:.1f}\"\n",
    "        })\n",
    "\n",
    "        print(f\"‚úÖ {name}:\")\n",
    "        print(f\"   MAPE: {mape_score:.4f} (lower is better)\")\n",
    "        print(f\"   RMSE: ${rmse_score:.2f}\")\n",
    "        print(f\"   MAE:  ${mae_score:.2f}\")\n",
    "        print(f\"   Training Time: {training_times[name]:.1f}s\")\n",
    "        print()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error evaluating {name}: {str(e)}\")\n",
    "\n",
    "# Create results DataFrame\n",
    "eval_df = pd.DataFrame(evaluation_data)\n",
    "print(\"üìã Summary Table:\")\n",
    "display(eval_df)\n",
    "\n",
    "# Find best model\n",
    "if results:\n",
    "    best_model = min(results.keys(), key=lambda k: results[k]['MAPE'])\n",
    "    print(f\"\\nüèÜ Best Model: {best_model}\")\n",
    "    print(f\"   MAPE: {results[best_model]['MAPE']:.4f}\")\n",
    "    print(f\"   Training Time: {results[best_model]['Training_Time']:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualization",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "outputId": "970466aa-379a-4db7-d667-fb1d801a6d07"
   },
   "outputs": [],
   "source": "# Visualization - Using Saved Models (Fixed Component Mismatch)\nprint(\"üìà Creating visualization using saved models...\")\nprint(\"=\"*50)\n\n# Load saved models for visualization (more robust than using in-memory models)\nviz_models = {}\nviz_predictions = {}\n\ndef load_model_for_viz(model_name, model_path):\n    \"\"\"Load a saved model for visualization\"\"\"\n    try:\n        if model_name.lower() == 'lightgbm':\n            from darts.models import LightGBMModel\n            return LightGBMModel.load(model_path)\n        elif model_name.lower() == 'exponentialsmoothing':\n            from darts.models import ExponentialSmoothing\n            return ExponentialSmoothing.load(model_path)\n        elif model_name.lower() == 'randomforest':\n            from darts.models import RandomForestModel\n            return RandomForestModel.load(model_path)\n        elif model_name.lower() == 'xgboost':\n            from darts.models import XGBModel\n            return XGBModel.load(model_path)\n        elif model_name.lower() == 'nbeats':\n            from darts.models import NBEATSModel\n            return NBEATSModel.load(model_path)\n        elif model_name.lower() == 'lstm':\n            from darts.models import RNNModel\n            return RNNModel.load(model_path)\n        elif model_name.lower() == 'tide_transformer':\n            from darts.models import TiDEModel\n            return TiDEModel.load(model_path)\n        elif model_name.lower() == 'tft':\n            from darts.models import TFTModel\n            return TFTModel.load(model_path)\n        else:\n            return None\n    except Exception as e:\n        print(f\"‚ùå Error loading {model_name}: {str(e)}\")\n        return None\n\n# Model files for visualization\nviz_model_files = {\n    'LightGBM': 'quantbase_models/lightgbm_model.pkl',\n    'ExponentialSmoothing': 'quantbase_models/exponential_smoothing_model.pkl',\n    'RandomForest': 'quantbase_models/random_forest_model.pkl',\n    'XGBoost': 'quantbase_models/xgboost_model.pkl',\n    'NBEATS': 'quantbase_models/nbeats_model.pkl',\n    'LSTM': 'quantbase_models/lstm_model.pkl',\n    'TiDE_Transformer': 'quantbase_models/tide_transformer_model.pkl',\n    'TFT': 'quantbase_models/tft_model.pkl'\n}\n\nprint(\"üîç Loading saved models for visualization...\")\nviz_models_loaded = 0\n\nfor model_name, model_path in viz_model_files.items():\n    if os.path.exists(model_path):\n        loaded_model = load_model_for_viz(model_name, model_path)\n        if loaded_model is not None:\n            viz_models[model_name] = loaded_model\n            viz_models_loaded += 1\n            print(f\"   ‚úÖ Loaded {model_name}\")\n\nprint(f\"üì¶ Loaded {viz_models_loaded} models for visualization\")\n\nif viz_models_loaded > 0:\n    print(\"\\nüîÆ Generating predictions for visualization...\")\n    \n    # Generate predictions from saved models\n    for model_name, model in viz_models.items():\n        try:\n            print(f\"   Predicting with {model_name}...\")\n            \n            # Handle different model input requirements and ensure correct prediction length\n            if model_name == 'LightGBM':\n                # LightGBM was trained on multivariate data\n                prediction = model.predict(n=len(test_series), series=train_multi)\n                # Extract only Close component and ensure correct length\n                if prediction.n_components > 1:\n                    prediction = prediction.univariate_component('Close')\n                # Trim to test_series length if needed\n                if len(prediction) > len(test_series):\n                    prediction = prediction[-len(test_series):]\n                elif len(prediction) < len(test_series):\n                    # If prediction is shorter, predict again with series parameter\n                    prediction = model.predict(n=len(test_series))\n                    if prediction.n_components > 1:\n                        prediction = prediction.univariate_component('Close')\n            \n            elif model_name == 'RandomForest':\n                # RandomForest was trained on multivariate data\n                prediction = model.predict(n=len(test_series), series=train_multi)\n                # Extract only Close component and ensure correct length\n                if prediction.n_components > 1:\n                    prediction = prediction.univariate_component('Close')\n                # Trim to test_series length if needed\n                if len(prediction) > len(test_series):\n                    prediction = prediction[-len(test_series):]\n            \n            elif model_name == 'ExponentialSmoothing':\n                # Exponential Smoothing uses only close price\n                prediction = model.predict(n=len(test_series), series=train_series)\n                # Ensure correct length\n                if len(prediction) > len(test_series):\n                    prediction = prediction[-len(test_series):]\n            \n            else:\n                # Other models (NBEATS, LSTM, TiDE, TFT, XGBoost) use close price\n                prediction = model.predict(n=len(test_series), series=train_series)\n                # Ensure univariate if needed\n                if prediction.n_components > 1:\n                    if 'Close' in prediction.components:\n                        prediction = prediction.univariate_component('Close')\n                    else:\n                        prediction = prediction.univariate_component(0)  # Take first component\n                # Ensure correct length\n                if len(prediction) > len(test_series):\n                    prediction = prediction[-len(test_series):]\n            \n            # Final length check and adjustment\n            if len(prediction) != len(test_series):\n                print(f\"   ‚ö†Ô∏è  Length mismatch for {model_name}: pred={len(prediction)}, test={len(test_series)}\")\n                # Try to align the prediction with test series dates\n                if len(prediction) > len(test_series):\n                    prediction = prediction[-len(test_series):]\n                else:\n                    # Skip this model if we can't get the right length\n                    print(f\"   ‚ùå Skipping {model_name} due to length mismatch\")\n                    continue\n            \n            viz_predictions[model_name] = prediction\n            print(f\"   ‚úÖ {model_name} predictions generated (length: {len(prediction)})\")\n            \n        except Exception as e:\n            print(f\"   ‚ùå Error generating predictions for {model_name}: {str(e)}\")\n            import traceback\n            traceback.print_exc()\n    \n    # Create visualization using saved models\n    if viz_predictions:\n        plt.figure(figsize=(16, 10))\n        \n        # Plot actual values\n        actual_values = test_series.values().flatten()\n        actual_dates = test_series.time_index\n        plt.plot(actual_dates, actual_values,\n                 label='Actual BTC Price', color='black', linewidth=3, alpha=0.8)\n        \n        print(f\"\\nüìä Plotting {len(viz_predictions)} model predictions...\")\n        \n        # Plot predictions from saved models\n        colors = ['red', 'blue', 'green', 'orange', 'purple', 'brown', 'pink', 'gray']\n        linestyles = ['--', '-.', ':', '--', '-.', ':', '--', '-.']\n        \n        for i, (model_name, prediction) in enumerate(viz_predictions.items()):\n            try:\n                pred_values = prediction.values().flatten()\n                pred_dates = prediction.time_index\n                \n                # Ensure dates and values have same length\n                if len(pred_dates) != len(pred_values):\n                    print(f\"   ‚ö†Ô∏è  Date/value mismatch for {model_name}: dates={len(pred_dates)}, values={len(pred_values)}\")\n                    min_len = min(len(pred_dates), len(pred_values))\n                    pred_dates = pred_dates[:min_len]\n                    pred_values = pred_values[:min_len]\n                \n                # Calculate MAPE score for the label\n                try:\n                    mape_score = mape(test_series, prediction)\n                except Exception as mape_error:\n                    print(f\"   ‚ö†Ô∏è  MAPE calculation failed for {model_name}: {str(mape_error)}\")\n                    mape_score = 0.0\n                \n                plt.plot(pred_dates, pred_values,\n                         label=f'{model_name} (MAPE: {mape_score:.4f})',\n                         color=colors[i % len(colors)],\n                         linestyle=linestyles[i % len(linestyles)],\n                         linewidth=2, alpha=0.9)\n                \n                print(f\"   ‚úÖ Plotted {model_name} (MAPE: {mape_score:.4f})\")\n                \n            except Exception as plot_error:\n                print(f\"   ‚ùå Error plotting {model_name}: {str(plot_error)}\")\n        \n        plt.title('QuantBase ML Models - Bitcoin Price Predictions\\n(Using Saved Models - Component-Safe Approach)',\n                  fontsize=16, fontweight='bold')\n        plt.xlabel('Date', fontsize=12)\n        plt.ylabel('Price (USD)', fontsize=12)\n        plt.legend(loc='upper left', fontsize=10)\n        plt.grid(True, alpha=0.3)\n        plt.xticks(rotation=45)\n        plt.tight_layout()\n        \n        # Add performance text\n        if 'total_training_time' in globals() and 'best_model' in globals():\n            text_str = f\"Training completed in {total_training_time:.1f}s\\n\"\n            text_str += f\"Best model: {best_model}\\n\"\n        else:\n            text_str = f\"Models loaded from files: {viz_models_loaded}\\n\"\n        text_str += f\"Predictions plotted: {len(viz_predictions)}\\n\"\n        text_str += f\"GPU: {torch.cuda.is_available()}\\n\"\n        text_str += f\"Data source: Saved models\"\n        plt.text(0.02, 0.98, text_str, transform=plt.gca().transAxes,\n                 verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))\n        \n        plt.show()\n        \n        print(\"‚úÖ Visualization complete using saved models!\")\n        print(\"üìä This approach demonstrates:\")\n        print(\"   ‚Ä¢ Loading models from saved files\")\n        print(\"   ‚Ä¢ Handling multivariate vs univariate predictions\")\n        print(\"   ‚Ä¢ Component extraction and length alignment\")\n        print(\"   ‚Ä¢ Robust error handling and plotting\")\n        \n    else:\n        print(\"‚ùå No predictions could be generated for visualization!\")\n        \nelse:\n    print(\"‚ùå No saved models found for visualization!\")\n    print(\"üí° Please run the training cells first to save models.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "future-predictions",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "3445e36403184c4daee77379e9946350",
      "22ddfa8f380a442186375367710a1b24",
      "bc0d3af2ba564869848a3b356495cf85",
      "fba0460fed9a46c5aff7aaf6f343adf4",
      "ac72bd63c9f94209b7a6b3acf0fe9b98",
      "6cd4a1e53359468caa89c65b70307d05",
      "c90bc4ddd95b48b4aec2e54b86e20ec1",
      "c60034acdd20465998f6dfd182270dc1",
      "233b225a26934a4fb069aa57e916cad6",
      "7307c0ba5bf2436e858fe97f3b8a2342",
      "658f1ffa4fdb457c826161e2d9409f66",
      "27e4a142bc5948dfad67c2d12cac4cb4",
      "cd9d732d8ed0443f9a860820053f03b6",
      "88f8387b62ba4937801292e171e8a90b",
      "a5ec82af667a4b0fb5d13047acf1119a",
      "8506740c4e154365b82a2faf203596c6",
      "a0ea10846cb94375836f242a512cc4a4",
      "f669ee2387ef482b97aaf483f5e6e082",
      "245483d83c1d4d3f897b6260db218482",
      "708aff0db6e7453ca4857fceffd66d3b",
      "10f8fda185d14e91a43c552da05b9c99",
      "13686687430f4741b9600aafbfbbc5e5"
     ]
    },
    "outputId": "b2668e10-5448-403d-8339-deb38dc74a43"
   },
   "outputs": [],
   "source": "# Generate Future Predictions (7 days ahead) - Using Saved Models\nprint(\"üîÆ Generating 7-day future predictions from saved models...\")\nprint(\"=\"*60)\n\n# Load saved models for future predictions (robust approach)\nfuture_models = {}\nfuture_predictions = {}\n\ndef load_model_for_future(model_name, model_path):\n    \"\"\"Load a saved model for future predictions\"\"\"\n    try:\n        if model_name.lower() == 'lightgbm':\n            from darts.models import LightGBMModel\n            return LightGBMModel.load(model_path)\n        elif model_name.lower() == 'exponentialsmoothing':\n            from darts.models import ExponentialSmoothing\n            return ExponentialSmoothing.load(model_path)\n        elif model_name.lower() == 'randomforest':\n            from darts.models import RandomForestModel\n            return RandomForestModel.load(model_path)\n        elif model_name.lower() == 'xgboost':\n            from darts.models import XGBModel\n            return XGBModel.load(model_path)\n        elif model_name.lower() == 'nbeats':\n            from darts.models import NBEATSModel\n            return NBEATSModel.load(model_path)\n        elif model_name.lower() == 'lstm':\n            from darts.models import RNNModel\n            return RNNModel.load(model_path)\n        elif model_name.lower() == 'tide_transformer':\n            from darts.models import TiDEModel\n            return TiDEModel.load(model_path)\n        elif model_name.lower() == 'tft':\n            from darts.models import TFTModel\n            return TFTModel.load(model_path)\n        else:\n            return None\n    except Exception as e:\n        print(f\"‚ùå Error loading {model_name}: {str(e)}\")\n        return None\n\n# Model files for future predictions\nfuture_model_files = {\n    'LightGBM': 'quantbase_models/lightgbm_model.pkl',\n    'ExponentialSmoothing': 'quantbase_models/exponential_smoothing_model.pkl',\n    'RandomForest': 'quantbase_models/random_forest_model.pkl',\n    'XGBoost': 'quantbase_models/xgboost_model.pkl',\n    'NBEATS': 'quantbase_models/nbeats_model.pkl',\n    'LSTM': 'quantbase_models/lstm_model.pkl',\n    'TiDE_Transformer': 'quantbase_models/tide_transformer_model.pkl',\n    'TFT': 'quantbase_models/tft_model.pkl'\n}\n\nprint(\"üîç Loading saved models for future predictions...\")\nfuture_models_loaded = 0\n\nfor model_name, model_path in future_model_files.items():\n    if os.path.exists(model_path):\n        loaded_model = load_model_for_future(model_name, model_path)\n        if loaded_model is not None:\n            future_models[model_name] = loaded_model\n            future_models_loaded += 1\n            print(f\"   ‚úÖ Loaded {model_name}\")\n\nprint(f\"üì¶ Loaded {future_models_loaded} models for future predictions\")\n\nif future_models_loaded > 0:\n    # Generate forecast dates (7 days into the future)\n    forecast_dates = pd.date_range(start=close_series.time_index[-1] + pd.Timedelta(days=1),\n                                   periods=7, freq='D')\n    \n    print(f\"\\nüîÆ Generating 7-day forecasts from {forecast_dates[0].strftime('%Y-%m-%d')} to {forecast_dates[-1].strftime('%Y-%m-%d')}...\")\n    \n    # Generate future predictions from saved models\n    for model_name, model in future_models.items():\n        try:\n            print(f\"   Forecasting with {model_name}...\")\n            \n            # Handle different model input requirements for future predictions\n            if model_name == 'LightGBM':\n                # LightGBM was trained on multivariate data - use full multivariate series\n                future_pred = model.predict(n=7, series=multi_series)\n                # Extract only Close component\n                if future_pred.n_components > 1:\n                    future_pred = future_pred.univariate_component('Close')\n                future_pred_values = future_pred.values().flatten()\n            \n            elif model_name == 'RandomForest':\n                # RandomForest was trained on multivariate data - use full multivariate series\n                future_pred = model.predict(n=7, series=multi_series)\n                # Extract only Close component\n                if future_pred.n_components > 1:\n                    future_pred = future_pred.univariate_component('Close')\n                future_pred_values = future_pred.values().flatten()\n            \n            elif model_name == 'ExponentialSmoothing':\n                # Exponential Smoothing uses only close price - use full close series\n                future_pred = model.predict(n=7, series=close_series)\n                future_pred_values = future_pred.values().flatten()\n            \n            else:\n                # Other models (NBEATS, LSTM, TiDE, TFT, XGBoost) use close price - use full close series\n                future_pred = model.predict(n=7, series=close_series)\n                # Ensure univariate if needed\n                if future_pred.n_components > 1:\n                    if 'Close' in future_pred.components:\n                        future_pred = future_pred.univariate_component('Close')\n                    else:\n                        future_pred = future_pred.univariate_component(0)  # Take first component\n                future_pred_values = future_pred.values().flatten()\n            \n            # Ensure we have exactly 7 predictions\n            if len(future_pred_values) != 7:\n                print(f\"   ‚ö†Ô∏è  Expected 7 predictions, got {len(future_pred_values)} for {model_name}\")\n                if len(future_pred_values) > 7:\n                    future_pred_values = future_pred_values[:7]\n                else:\n                    print(f\"   ‚ùå Skipping {model_name} due to insufficient predictions\")\n                    continue\n            \n            future_predictions[model_name] = future_pred_values\n            \n            # Show the final prediction (7 days from now)\n            final_price = future_pred_values[-1]\n            current_price = close_series.values()[-1][0]  # Get last actual price\n            change_pct = ((final_price - current_price) / current_price) * 100\n            \n            print(f\"   ‚úÖ {model_name}: ${final_price:.2f} (7 days from now)\")\n            print(f\"      Change from current: {change_pct:+.2f}%\")\n            \n        except Exception as e:\n            print(f\"   ‚ùå Error generating future prediction for {model_name}: {str(e)}\")\n            import traceback\n            traceback.print_exc()\n    \n    # Create future predictions DataFrame and display results\n    if future_predictions:\n        future_df = pd.DataFrame(future_predictions, index=forecast_dates)\n        \n        print(f\"\\nüìÖ 7-Day Forecast Summary ({len(future_predictions)} models):\")\n        print(\"=\"*60)\n        \n        # Show current price for reference\n        current_price = close_series.values()[-1][0]\n        print(f\"Current BTC Price: ${current_price:.2f}\")\n        print(f\"Forecast Period: {forecast_dates[0].strftime('%Y-%m-%d')} to {forecast_dates[-1].strftime('%Y-%m-%d')}\")\n        print()\n        \n        # Display the forecast table\n        display(future_df.round(2))\n        \n        # Calculate ensemble forecast (average of all models)\n        ensemble_forecast = future_df.mean(axis=1)\n        ensemble_final = ensemble_forecast.iloc[-1]\n        ensemble_change = ((ensemble_final - current_price) / current_price) * 100\n        \n        print(f\"\\nüìä Ensemble Forecast (Average of {len(future_predictions)} models):\")\n        print(f\"   7-day target: ${ensemble_final:.2f}\")\n        print(f\"   Expected change: {ensemble_change:+.2f}%\")\n        \n        # Find most bullish and bearish predictions\n        final_day_predictions = future_df.iloc[-1]\n        most_bullish = final_day_predictions.idxmax()\n        most_bearish = final_day_predictions.idxmin()\n        bullish_price = final_day_predictions[most_bullish]\n        bearish_price = final_day_predictions[most_bearish]\n        \n        print(f\"\\nüêÇ Most Bullish: {most_bullish} (${bullish_price:.2f})\")\n        print(f\"üêª Most Bearish: {most_bearish} (${bearish_price:.2f})\")\n        print(f\"üìà Price Range: ${bearish_price:.2f} - ${bullish_price:.2f}\")\n        \n        # Create future predictions visualization\n        print(\"\\nüìà Creating future predictions visualization...\")\n        plt.figure(figsize=(14, 8))\n        \n        # Plot recent actual data (last 30 days for context)\n        recent_data = close_series[-30:]\n        plt.plot(recent_data.time_index, recent_data.values(),\n                 label='Recent Actual', color='black', linewidth=3, alpha=0.8)\n        \n        # Plot future predictions from each saved model\n        colors = ['red', 'blue', 'green', 'orange', 'purple', 'brown', 'pink', 'gray']\n        for i, (model_name, pred_values) in enumerate(future_predictions.items()):\n            plt.plot(forecast_dates, pred_values,\n                     label=f'{model_name} Forecast',\n                     color=colors[i % len(colors)],\n                     marker='o', linewidth=2, alpha=0.8, markersize=4)\n        \n        # Plot ensemble forecast\n        plt.plot(forecast_dates, ensemble_forecast.values,\n                 label='Ensemble (Average)', color='gold',\n                 marker='s', linewidth=3, alpha=0.9, markersize=6)\n        \n        # Add vertical line at prediction start\n        plt.axvline(x=recent_data.time_index[-1], color='red', linestyle=':', alpha=0.7,\n                    label='Prediction Start')\n        \n        plt.title('Bitcoin Price - 7-Day Future Predictions\\n(Using Saved Models)', \n                  fontsize=14, fontweight='bold')\n        plt.xlabel('Date')\n        plt.ylabel('Price (USD)')\n        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n        plt.grid(True, alpha=0.3)\n        plt.xticks(rotation=45)\n        plt.tight_layout()\n        \n        # Add forecast summary text\n        text_str = f\"Models: {len(future_predictions)}\\n\"\n        text_str += f\"Current: ${current_price:.2f}\\n\"\n        text_str += f\"Ensemble 7d: ${ensemble_final:.2f}\\n\"\n        text_str += f\"Change: {ensemble_change:+.2f}%\"\n        plt.text(0.02, 0.98, text_str, transform=plt.gca().transAxes,\n                 verticalalignment='top', bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.8))\n        \n        plt.show()\n        \n        # Save future predictions to CSV\n        try:\n            os.makedirs('quantbase_results', exist_ok=True)\n            future_df.to_csv('quantbase_results/saved_models_future_predictions.csv')\n            print(\"‚úÖ Saved future predictions to quantbase_results/saved_models_future_predictions.csv\")\n            \n            # Save ensemble forecast\n            ensemble_df = pd.DataFrame({'Ensemble_Forecast': ensemble_forecast})\n            ensemble_df.to_csv('quantbase_results/ensemble_forecast.csv')\n            print(\"‚úÖ Saved ensemble forecast to quantbase_results/ensemble_forecast.csv\")\n            \n        except Exception as e:\n            print(f\"‚ùå Error saving predictions: {str(e)}\")\n        \n        print(\"\\nüéØ Future Predictions Summary:\")\n        print(\"=\"*50)\n        print(\"‚úÖ Successfully loaded models from saved files\")\n        print(\"‚úÖ Generated 7-day forecasts for all available models\")\n        print(\"‚úÖ Created ensemble forecast from multiple models\")\n        print(\"‚úÖ Visualized predictions with recent price context\")\n        print(\"‚úÖ Saved predictions to CSV files\")\n        \n    else:\n        print(\"‚ùå No future predictions could be generated!\")\n        \nelse:\n    print(\"‚ùå No saved models found for future predictions!\")\n    print(\"üí° Please run the training cells first to save models.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save-models"
   },
   "outputs": [],
   "source": [
    "# Save Models and Results\n",
    "print(\"üíæ Saving models and results...\")\n",
    "\n",
    "# Create directories\n",
    "os.makedirs('quantbase_models', exist_ok=True)\n",
    "os.makedirs('quantbase_results', exist_ok=True)\n",
    "\n",
    "# Save models\n",
    "for name, model in models.items():\n",
    "    try:\n",
    "        model_path = f'quantbase_models/{name.lower()}_model.pkl'\n",
    "        model.save(model_path)\n",
    "        print(f\"‚úÖ Saved {name} model to {model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error saving {name}: {str(e)}\")\n",
    "\n",
    "# Save evaluation results\n",
    "eval_df.to_csv('quantbase_results/model_evaluation.csv', index=False)\n",
    "print(\"‚úÖ Saved evaluation results to quantbase_results/model_evaluation.csv\")\n",
    "\n",
    "# Save future predictions\n",
    "future_df.to_csv('quantbase_results/future_predictions.csv')\n",
    "print(\"‚úÖ Saved future predictions to quantbase_results/future_predictions.csv\")\n",
    "\n",
    "# Save processed data\n",
    "btc_data.to_csv('quantbase_results/processed_btc_data.csv')\n",
    "print(\"‚úÖ Saved processed data to quantbase_results/processed_btc_data.csv\")\n",
    "\n",
    "print(\"\\nüì¶ All files saved! You can download them from the file panel.\")\n",
    "\n",
    "# Create a simple prediction function for teammates\n",
    "prediction_code = f'''\n",
    "# QuantBase Model Interface - Copy this to your project\n",
    "from darts.models import load_model\n",
    "import pandas as pd\n",
    "\n",
    "def get_bitcoin_prediction(days=7, model_name=\"{best_model.lower()}\"):\n",
    "    \"\"\"Get Bitcoin price prediction using trained models\"\"\"\n",
    "    try:\n",
    "        model = load_model(f\"quantbase_models/{{model_name}}_model.pkl\")\n",
    "        # Load your latest data here\n",
    "        # prediction = model.predict(n=days)\n",
    "        # return prediction.values().flatten()\n",
    "        return \"Model loaded successfully! Integrate with your live data.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {{str(e)}}\"\n",
    "\n",
    "# Example usage:\n",
    "# predictions = get_bitcoin_prediction(7, \"{best_model.lower()}\")\n",
    "'''\n",
    "\n",
    "with open('quantbase_results/model_interface.py', 'w') as f:\n",
    "    f.write(prediction_code)\n",
    "\n",
    "print(\"‚úÖ Saved model interface code to quantbase_results/model_interface.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "summary"
   },
   "outputs": [],
   "source": [
    "# Final Summary\n",
    "print(\"üéâ QuantBase ML Training Complete!\")\n",
    "print(\"=\"*50)\n",
    "print(f\"üìä Trained {len(models)} models in {total_training_time:.1f} seconds\")\n",
    "print(f\"üèÜ Best model: {best_model} (MAPE: {results[best_model]['MAPE']:.4f})\")\n",
    "print(f\"üöÄ GPU acceleration: {'Enabled' if torch.cuda.is_available() else 'Not available'}\")\n",
    "\n",
    "print(\"\\nüìÅ Files created:\")\n",
    "print(\"   ‚Ä¢ quantbase_models/ - Trained model files\")\n",
    "print(\"   ‚Ä¢ quantbase_results/ - Evaluation results and predictions\")\n",
    "print(\"   ‚Ä¢ model_interface.py - Code for your teammates\")\n",
    "\n",
    "print(\"\\nüîó Next steps:\")\n",
    "print(\"   1. Download all files using the file panel\")\n",
    "print(\"   2. Upload models to your QuantBase project\")\n",
    "print(\"   3. Use model_interface.py for predictions\")\n",
    "print(\"   4. Integrate with your marketplace platform\")\n",
    "\n",
    "print(\"\\n‚ú® Ready for your hackathon demo!\")\n",
    "\n",
    "# Show final performance comparison\n",
    "print(\"\\nüìà Final Model Comparison:\")\n",
    "for name in results.keys():\n",
    "    mape = results[name]['MAPE']\n",
    "    time_taken = results[name]['Training_Time']\n",
    "    print(f\"   {name}: MAPE={mape:.4f}, Time={time_taken:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Evaluation Cell - Load Saved Models and Re-evaluate\nprint(\"üîÑ Loading Saved Models for Fresh Evaluation\")\nprint(\"=\"*60)\n\n# This cell demonstrates how to load saved models and evaluate them\n# This is useful for:\n# 1. Re-running evaluation after restarting notebook\n# 2. Loading models saved in previous sessions\n# 3. Verifying model persistence and loading works correctly\n\nsaved_models = {}\nsaved_predictions = {}\nsaved_evaluation_results = {}\n\n# Model loading functions\ndef load_saved_model(model_name, model_path):\n    \"\"\"Load a saved model from file\"\"\"\n    try:\n        if model_name.lower() == 'lightgbm':\n            from darts.models import LightGBMModel\n            return LightGBMModel.load(model_path)\n        elif model_name.lower() == 'exponentialsmoothing':\n            from darts.models import ExponentialSmoothing\n            return ExponentialSmoothing.load(model_path)\n        elif model_name.lower() == 'randomforest':\n            from darts.models import RandomForestModel\n            return RandomForestModel.load(model_path)\n        elif model_name.lower() == 'xgboost':\n            from darts.models import XGBModel\n            return XGBModel.load(model_path)\n        elif model_name.lower() == 'nbeats':\n            from darts.models import NBEATSModel\n            return NBEATSModel.load(model_path)\n        elif model_name.lower() == 'lstm':\n            from darts.models import RNNModel\n            return RNNModel.load(model_path)\n        elif model_name.lower() == 'tide_transformer':\n            from darts.models import TiDEModel\n            return TiDEModel.load(model_path)\n        elif model_name.lower() == 'tft':\n            from darts.models import TFTModel\n            return TFTModel.load(model_path)\n        else:\n            print(f\"‚ö†Ô∏è  Unknown model type: {model_name}\")\n            return None\n    except Exception as e:\n        print(f\"‚ùå Error loading {model_name}: {str(e)}\")\n        return None\n\n# Model files to look for\nmodel_files = {\n    'LightGBM': 'quantbase_models/lightgbm_model.pkl',\n    'ExponentialSmoothing': 'quantbase_models/exponential_smoothing_model.pkl',\n    'RandomForest': 'quantbase_models/random_forest_model.pkl',\n    'XGBoost': 'quantbase_models/xgboost_model.pkl',\n    'NBEATS': 'quantbase_models/nbeats_model.pkl',\n    'LSTM': 'quantbase_models/lstm_model.pkl',\n    'TiDE_Transformer': 'quantbase_models/tide_transformer_model.pkl',\n    'TFT': 'quantbase_models/tft_model.pkl'\n}\n\nprint(\"üîç Discovering and loading saved models...\")\nmodels_loaded = 0\n\nfor model_name, model_path in model_files.items():\n    if os.path.exists(model_path):\n        print(f\"   Found: {model_path}\")\n        loaded_model = load_saved_model(model_name, model_path)\n        if loaded_model is not None:\n            saved_models[model_name] = loaded_model\n            models_loaded += 1\n            print(f\"   ‚úÖ Loaded {model_name}\")\n        else:\n            print(f\"   ‚ùå Failed to load {model_name}\")\n    else:\n        print(f\"   Missing: {model_path}\")\n\nprint(f\"\\nüì¶ Successfully loaded {models_loaded} saved models\")\n\nif models_loaded == 0:\n    print(\"‚ö†Ô∏è  No saved models found! Please run training cells first.\")\nelse:\n    print(\"\\nüîÆ Generating fresh predictions from saved models...\")\n    \n    # Generate predictions using loaded models\n    for model_name, model in saved_models.items():\n        try:\n            print(f\"   Predicting with {model_name}...\")\n            \n            # Handle different model input requirements\n            if model_name == 'LightGBM':\n                # LightGBM was trained on multivariate data\n                prediction = model.predict(n=len(test_series))\n                prediction = prediction.univariate_component('Close')\n            elif model_name == 'ExponentialSmoothing':\n                # Exponential Smoothing uses only close price\n                prediction = model.predict(n=len(test_series))\n            else:\n                # Other models use close price\n                prediction = model.predict(n=len(test_series))\n            \n            saved_predictions[model_name] = prediction\n            print(f\"   ‚úÖ {model_name} predictions generated\")\n            \n        except Exception as e:\n            print(f\"   ‚ùå Error generating predictions for {model_name}: {str(e)}\")\n    \n    # Evaluate saved model predictions\n    print(f\"\\nüìä Evaluating {len(saved_predictions)} saved models...\")\n    print(\"=\"*50)\n    \n    saved_eval_data = []\n    \n    for model_name, prediction in saved_predictions.items():\n        try:\n            # Calculate metrics\n            mape_score = mape(test_series, prediction)\n            rmse_score = rmse(test_series, prediction)\n            mae_score = mae(test_series, prediction)\n            \n            # Store results\n            saved_evaluation_results[model_name] = {\n                'MAPE': mape_score,\n                'RMSE': rmse_score,\n                'MAE': mae_score\n            }\n            \n            saved_eval_data.append({\n                'Model': model_name,\n                'MAPE': f\"{mape_score:.4f}\",\n                'RMSE': f\"{rmse_score:.2f}\",\n                'MAE': f\"{mae_score:.2f}\"\n            })\n            \n            print(f\"‚úÖ {model_name}:\")\n            print(f\"   MAPE: {mape_score:.4f} (lower is better)\")\n            print(f\"   RMSE: ${rmse_score:.2f}\")\n            print(f\"   MAE:  ${mae_score:.2f}\")\n            print()\n            \n        except Exception as e:\n            print(f\"‚ùå Error evaluating {model_name}: {str(e)}\")\n    \n    # Display results table\n    if saved_eval_data:\n        saved_eval_df = pd.DataFrame(saved_eval_data)\n        print(\"üìã Saved Models Evaluation Summary:\")\n        display(saved_eval_df)\n        \n        # Find best saved model\n        best_saved_model = min(saved_evaluation_results.keys(), \n                              key=lambda k: saved_evaluation_results[k]['MAPE'])\n        print(f\"\\nüèÜ Best Saved Model: {best_saved_model}\")\n        print(f\"   MAPE: {saved_evaluation_results[best_saved_model]['MAPE']:.4f}\")\n        \n        # Save fresh evaluation results\n        saved_eval_df.to_csv('quantbase_results/saved_models_evaluation.csv', index=False)\n        print(f\"\\nüíæ Saved fresh evaluation results to quantbase_results/saved_models_evaluation.csv\")\n        \n        # Create visualization of saved model predictions\n        print(\"\\nüìà Creating saved models visualization...\")\n        plt.figure(figsize=(16, 10))\n        \n        # Plot actual values\n        actual_values = test_series.values().flatten()\n        actual_dates = test_series.time_index\n        plt.plot(actual_dates, actual_values,\n                 label='Actual BTC Price', color='black', linewidth=3, alpha=0.8)\n        \n        # Plot saved model predictions\n        colors = ['red', 'blue', 'green', 'orange', 'purple', 'brown', 'pink', 'gray']\n        linestyles = ['--', '-.', ':', '--', '-.', ':', '--', '-.']\n        \n        for i, (model_name, prediction) in enumerate(saved_predictions.items()):\n            pred_values = prediction.values().flatten()\n            pred_dates = prediction.time_index\n            \n            mape_score = saved_evaluation_results[model_name]['MAPE']\n            \n            plt.plot(pred_dates, pred_values,\n                     label=f'{model_name} (MAPE: {mape_score:.4f})',\n                     color=colors[i % len(colors)],\n                     linestyle=linestyles[i % len(linestyles)],\n                     linewidth=2, alpha=0.9)\n        \n        plt.title('QuantBase Saved Models - Bitcoin Price Predictions\\n(Loaded from Saved Files)',\n                  fontsize=16, fontweight='bold')\n        plt.xlabel('Date', fontsize=12)\n        plt.ylabel('Price (USD)', fontsize=12)\n        plt.legend(loc='upper left', fontsize=10)\n        plt.grid(True, alpha=0.3)\n        plt.xticks(rotation=45)\n        plt.tight_layout()\n        \n        # Add info text\n        text_str = f\"Models loaded: {models_loaded}\\n\"\n        text_str += f\"Best model: {best_saved_model}\\n\"\n        text_str += f\"Evaluation: Fresh predictions\"\n        plt.text(0.02, 0.98, text_str, transform=plt.gca().transAxes,\n                 verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n        \n        plt.show()\n        \n        print(\"‚úÖ Saved models evaluation complete!\")\n    else:\n        print(\"‚ùå No saved models could be evaluated\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Export Trading Bot Data - Comprehensive CSV Exports\nprint(\"üì§ Exporting Prediction Data for Trading Bot\")\nprint(\"=\"*60)\n\n# This cell exports all prediction data in formats optimized for algorithmic trading\n# Your friend can use these CSV files to feed data into the trading bot\n\n# Create comprehensive exports directory\nimport os\nos.makedirs('quantbase_trading_data', exist_ok=True)\nos.makedirs('quantbase_trading_data/predictions', exist_ok=True)\nos.makedirs('quantbase_trading_data/models', exist_ok=True)\nos.makedirs('quantbase_trading_data/analysis', exist_ok=True)\n\nprint(\"üîç Loading saved models for comprehensive data export...\")\n\n# Load all available saved models\nexport_models = {}\nexport_predictions = {}\n\ndef load_model_for_export(model_name, model_path):\n    \"\"\"Load a saved model for data export\"\"\"\n    try:\n        if model_name.lower() == 'lightgbm':\n            from darts.models import LightGBMModel\n            return LightGBMModel.load(model_path)\n        elif model_name.lower() == 'exponentialsmoothing':\n            from darts.models import ExponentialSmoothing\n            return ExponentialSmoothing.load(model_path)\n        elif model_name.lower() == 'randomforest':\n            from darts.models import RandomForestModel\n            return RandomForestModel.load(model_path)\n        elif model_name.lower() == 'xgboost':\n            from darts.models import XGBModel\n            return XGBModel.load(model_path)\n        elif model_name.lower() == 'nbeats':\n            from darts.models import NBEATSModel\n            return NBEATSModel.load(model_path)\n        elif model_name.lower() == 'lstm':\n            from darts.models import RNNModel\n            return RNNModel.load(model_path)\n        elif model_name.lower() == 'tide_transformer':\n            from darts.models import TiDEModel\n            return TiDEModel.load(model_path)\n        elif model_name.lower() == 'tft':\n            from darts.models import TFTModel\n            return TFTModel.load(model_path)\n        else:\n            return None\n    except Exception as e:\n        print(f\"‚ùå Error loading {model_name}: {str(e)}\")\n        return None\n\n# Model files for export\nexport_model_files = {\n    'LightGBM': 'quantbase_models/lightgbm_model.pkl',\n    'ExponentialSmoothing': 'quantbase_models/exponential_smoothing_model.pkl',\n    'RandomForest': 'quantbase_models/random_forest_model.pkl',\n    'XGBoost': 'quantbase_models/xgboost_model.pkl',\n    'NBEATS': 'quantbase_models/nbeats_model.pkl',\n    'LSTM': 'quantbase_models/lstm_model.pkl',\n    'TiDE_Transformer': 'quantbase_models/tide_transformer_model.pkl',\n    'TFT': 'quantbase_models/tft_model.pkl'\n}\n\nmodels_loaded = 0\nfor model_name, model_path in export_model_files.items():\n    if os.path.exists(model_path):\n        loaded_model = load_model_for_export(model_name, model_path)\n        if loaded_model is not None:\n            export_models[model_name] = loaded_model\n            models_loaded += 1\n            print(f\"   ‚úÖ Loaded {model_name}\")\n\nprint(f\"üì¶ Loaded {models_loaded} models for export\")\n\nif models_loaded > 0:\n    print(\"\\nüîÆ Generating predictions for trading bot export...\")\n    \n    # Generate historical predictions (backtest data)\n    for model_name, model in export_models.items():\n        try:\n            print(f\"   Generating predictions with {model_name}...\")\n            \n            # Handle different model input requirements\n            if model_name == 'LightGBM':\n                prediction = model.predict(n=len(test_series), series=train_multi)\n                if prediction.n_components > 1:\n                    prediction = prediction.univariate_component('Close')\n            elif model_name == 'RandomForest':\n                prediction = model.predict(n=len(test_series), series=train_multi)\n                if prediction.n_components > 1:\n                    prediction = prediction.univariate_component('Close')\n            elif model_name == 'ExponentialSmoothing':\n                prediction = model.predict(n=len(test_series), series=train_series)\n            else:\n                prediction = model.predict(n=len(test_series), series=train_series)\n                if prediction.n_components > 1:\n                    if 'Close' in prediction.components:\n                        prediction = prediction.univariate_component('Close')\n                    else:\n                        prediction = prediction.univariate_component(0)\n            \n            # Ensure correct length\n            if len(prediction) > len(test_series):\n                prediction = prediction[-len(test_series):]\n            elif len(prediction) < len(test_series):\n                print(f\"   ‚ö†Ô∏è  Skipping {model_name} due to length mismatch\")\n                continue\n            \n            export_predictions[model_name] = prediction\n            print(f\"   ‚úÖ {model_name} predictions ready for export\")\n            \n        except Exception as e:\n            print(f\"   ‚ùå Error generating predictions for {model_name}: {str(e)}\")\n    \n    if export_predictions:\n        print(f\"\\nüìä Exporting {len(export_predictions)} model predictions...\")\n        \n        # 1. Export individual model predictions\n        print(\"\\nüìÅ 1. Individual Model Predictions:\")\n        for model_name, prediction in export_predictions.items():\n            try:\n                # Create detailed prediction DataFrame\n                pred_df = pd.DataFrame({\n                    'timestamp': prediction.time_index,\n                    'predicted_price': prediction.values().flatten(),\n                    'model_name': model_name,\n                    'crypto_pair': TRAINING_CRYPTO\n                })\n                \n                # Add actual prices for comparison\n                actual_values = test_series.values().flatten()\n                if len(actual_values) == len(pred_df):\n                    pred_df['actual_price'] = actual_values\n                    pred_df['prediction_error'] = pred_df['predicted_price'] - pred_df['actual_price']\n                    pred_df['percentage_error'] = (pred_df['prediction_error'] / pred_df['actual_price']) * 100\n                \n                # Save individual model file\n                filename = f\"quantbase_trading_data/predictions/{model_name.lower()}_{TRAINING_CRYPTO.replace('-', '_')}_predictions.csv\"\n                pred_df.to_csv(filename, index=False)\n                print(f\"   ‚úÖ {model_name}: {filename}\")\n                \n            except Exception as e:\n                print(f\"   ‚ùå Error exporting {model_name}: {str(e)}\")\n        \n        # 2. Export combined predictions (master file for trading bot)\n        print(\"\\nüìÅ 2. Combined Predictions (Master Trading File):\")\n        try:\n            # Create master DataFrame with all model predictions\n            master_df = pd.DataFrame({\n                'timestamp': test_series.time_index,\n                'actual_price': test_series.values().flatten(),\n                'crypto_pair': TRAINING_CRYPTO\n            })\n            \n            # Add each model's predictions as columns\n            for model_name, prediction in export_predictions.items():\n                if len(prediction) == len(master_df):\n                    master_df[f'{model_name.lower()}_prediction'] = prediction.values().flatten()\n                    # Calculate individual model errors\n                    master_df[f'{model_name.lower()}_error'] = master_df[f'{model_name.lower()}_prediction'] - master_df['actual_price']\n                    master_df[f'{model_name.lower()}_error_pct'] = (master_df[f'{model_name.lower()}_error'] / master_df['actual_price']) * 100\n            \n            # Calculate ensemble prediction (average of all models)\n            prediction_cols = [col for col in master_df.columns if col.endswith('_prediction')]\n            master_df['ensemble_prediction'] = master_df[prediction_cols].mean(axis=1)\n            master_df['ensemble_error'] = master_df['ensemble_prediction'] - master_df['actual_price']\n            master_df['ensemble_error_pct'] = (master_df['ensemble_error'] / master_df['actual_price']) * 100\n            \n            # Add trading signals (basic example)\n            master_df['price_change_pct'] = master_df['actual_price'].pct_change() * 100\n            master_df['ensemble_signal'] = 'HOLD'\n            master_df.loc[master_df['ensemble_prediction'] > master_df['actual_price'] * 1.02, 'ensemble_signal'] = 'BUY'\n            master_df.loc[master_df['ensemble_prediction'] < master_df['actual_price'] * 0.98, 'ensemble_signal'] = 'SELL'\n            \n            # Save master trading file\n            master_filename = f\"quantbase_trading_data/predictions/MASTER_{TRAINING_CRYPTO.replace('-', '_')}_trading_data.csv\"\n            master_df.to_csv(master_filename, index=False)\n            print(f\"   ‚úÖ Master Trading File: {master_filename}\")\n            \n        except Exception as e:\n            print(f\"   ‚ùå Error creating master file: {str(e)}\")\n        \n        # 3. Export future predictions (7-day forecasts)\n        print(\"\\nüìÅ 3. Future Predictions (7-Day Forecasts):\")\n        try:\n            future_predictions_export = {}\n            forecast_dates = pd.date_range(start=close_series.time_index[-1] + pd.Timedelta(days=1), periods=7, freq='D')\n            \n            for model_name, model in export_models.items():\n                try:\n                    # Generate 7-day forecast\n                    if model_name == 'LightGBM':\n                        future_pred = model.predict(n=7, series=multi_series)\n                        if future_pred.n_components > 1:\n                            future_pred = future_pred.univariate_component('Close')\n                    elif model_name == 'RandomForest':\n                        future_pred = model.predict(n=7, series=multi_series)\n                        if future_pred.n_components > 1:\n                            future_pred = future_pred.univariate_component('Close')\n                    elif model_name == 'ExponentialSmoothing':\n                        future_pred = model.predict(n=7, series=close_series)\n                    else:\n                        future_pred = model.predict(n=7, series=close_series)\n                        if future_pred.n_components > 1:\n                            if 'Close' in future_pred.components:\n                                future_pred = future_pred.univariate_component('Close')\n                            else:\n                                future_pred = future_pred.univariate_component(0)\n                    \n                    future_predictions_export[model_name] = future_pred.values().flatten()\n                    \n                except Exception as e:\n                    print(f\"   ‚ö†Ô∏è  Error generating future predictions for {model_name}: {str(e)}\")\n            \n            if future_predictions_export:\n                # Create future predictions DataFrame\n                future_df = pd.DataFrame(future_predictions_export, index=forecast_dates)\n                future_df.index.name = 'forecast_date'\n                future_df['crypto_pair'] = TRAINING_CRYPTO\n                \n                # Add ensemble forecast\n                future_df['ensemble_forecast'] = future_df[[col for col in future_df.columns if col != 'crypto_pair']].mean(axis=1)\n                \n                # Add current price for reference\n                current_price = close_series.values()[-1][0]\n                future_df['current_price'] = current_price\n                \n                # Calculate expected changes\n                for col in future_df.columns:\n                    if col not in ['crypto_pair', 'current_price', 'forecast_date']:\n                        future_df[f'{col}_change_pct'] = ((future_df[col] - current_price) / current_price) * 100\n                \n                # Save future predictions\n                future_filename = f\"quantbase_trading_data/predictions/FUTURE_{TRAINING_CRYPTO.replace('-', '_')}_7day_forecasts.csv\"\n                future_df.to_csv(future_filename)\n                print(f\"   ‚úÖ Future Forecasts: {future_filename}\")\n            \n        except Exception as e:\n            print(f\"   ‚ùå Error creating future predictions: {str(e)}\")\n        \n        # 4. Export model performance metrics\n        print(\"\\nüìÅ 4. Model Performance Metrics:\")\n        try:\n            performance_data = []\n            \n            for model_name, prediction in export_predictions.items():\n                try:\n                    # Calculate metrics\n                    from darts.metrics import mape, rmse, mae\n                    mape_score = mape(test_series, prediction)\n                    rmse_score = rmse(test_series, prediction)\n                    mae_score = mae(test_series, prediction)\n                    \n                    # Calculate additional trading metrics\n                    pred_values = prediction.values().flatten()\n                    actual_values = test_series.values().flatten()\n                    \n                    # Directional accuracy (same direction as actual price movement)\n                    actual_direction = np.diff(actual_values) > 0\n                    pred_direction = np.diff(pred_values) > 0\n                    directional_accuracy = np.mean(actual_direction == pred_direction) * 100\n                    \n                    performance_data.append({\n                        'model_name': model_name,\n                        'crypto_pair': TRAINING_CRYPTO,\n                        'mape': mape_score,\n                        'rmse': rmse_score,\n                        'mae': mae_score,\n                        'directional_accuracy_pct': directional_accuracy,\n                        'test_period_days': len(prediction),\n                        'avg_prediction': np.mean(pred_values),\n                        'prediction_std': np.std(pred_values)\n                    })\n                    \n                except Exception as e:\n                    print(f\"   ‚ö†Ô∏è  Error calculating metrics for {model_name}: {str(e)}\")\n            \n            if performance_data:\n                performance_df = pd.DataFrame(performance_data)\n                performance_df = performance_df.sort_values('mape')  # Sort by best MAPE\n                \n                performance_filename = f\"quantbase_trading_data/analysis/model_performance_{TRAINING_CRYPTO.replace('-', '_')}.csv\"\n                performance_df.to_csv(performance_filename, index=False)\n                print(f\"   ‚úÖ Performance Metrics: {performance_filename}\")\n            \n        except Exception as e:\n            print(f\"   ‚ùå Error creating performance metrics: {str(e)}\")\n        \n        # 5. Export trading bot configuration\n        print(\"\\nüìÅ 5. Trading Bot Configuration:\")\n        try:\n            config_data = {\n                'crypto_pair': TRAINING_CRYPTO,\n                'training_crypto_name': crypto_name,\n                'models_available': list(export_models.keys()),\n                'best_model': min(export_predictions.keys(), key=lambda k: mape(test_series, export_predictions[k])) if export_predictions else None,\n                'data_points_trained': len(crypto_data),\n                'test_period_days': len(test_series),\n                'forecast_horizon_days': 7,\n                'last_update': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n                'model_files_location': 'quantbase_models/',\n                'prediction_files_location': 'quantbase_trading_data/predictions/',\n                'current_price': float(close_series.values()[-1][0]),\n                'price_range_min': float(crypto_data['Close'].min()),\n                'price_range_max': float(crypto_data['Close'].max())\n            }\n            \n            config_df = pd.DataFrame([config_data])\n            config_filename = f\"quantbase_trading_data/TRADING_BOT_CONFIG_{TRAINING_CRYPTO.replace('-', '_')}.csv\"\n            config_df.to_csv(config_filename, index=False)\n            print(f\"   ‚úÖ Trading Bot Config: {config_filename}\")\n            \n        except Exception as e:\n            print(f\"   ‚ùå Error creating trading bot config: {str(e)}\")\n        \n        print(f\"\\nüéâ Export Complete! Generated files for {TRAINING_CRYPTO} ({crypto_name}):\")\n        print(\"=\"*60)\n        print(\"üìÅ quantbase_trading_data/\")\n        print(\"   üìÅ predictions/\")\n        print(\"      üìÑ Individual model prediction files\")\n        print(\"      üìÑ MASTER trading data file (main file for your bot)\")\n        print(\"      üìÑ FUTURE 7-day forecasts\")\n        print(\"   üìÅ analysis/\")\n        print(\"      üìÑ Model performance metrics\")\n        print(\"   üìÑ TRADING_BOT_CONFIG file\")\n        print()\n        print(\"ü§ñ Your friend can now use these files in the trading bot!\")\n        print(\"üí° Start with the MASTER file for comprehensive trading data\")\n        \n    else:\n        print(\"‚ùå No predictions available for export!\")\n        \nelse:\n    print(\"‚ùå No saved models found for export!\")\n    print(\"üí° Please run the training cells first to save models.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Smart Download - Multiple Small ZIP Files (Colab-Friendly)\nprint(\"üì¶ Smart Download - Creating Multiple Small ZIP Files\")\nprint(\"=\"*70)\n\n# Create smaller ZIP files that are easier to download from Colab\nimport zipfile\nimport os\nimport shutil\nfrom datetime import datetime\n\ndef create_small_zip_chunks():\n    \"\"\"Create multiple small ZIP files for easier downloading\"\"\"\n    \n    # Clean up any existing zip files first\n    for file in os.listdir('.'):\n        if file.startswith('QuantBase_') and file.endswith('.zip'):\n            os.remove(file)\n            print(f\"üóëÔ∏è  Removed old ZIP: {file}\")\n    \n    timestamp = datetime.now().strftime('%Y%m%d_%H%M')\n    crypto_suffix = TRAINING_CRYPTO.replace('-', '_')\n    \n    zip_files_created = []\n    \n    # 1. ESSENTIAL FILES ZIP (Most Important - Download First!)\n    print(\"\\nüì¶ 1. Creating ESSENTIAL files ZIP...\")\n    essential_zip = f\"QuantBase_ESSENTIAL_{crypto_suffix}_{timestamp}.zip\"\n    \n    with zipfile.ZipFile(essential_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        # Master trading data (most important file)\n        essential_files = []\n        \n        if os.path.exists('quantbase_trading_data'):\n            for root, dirs, files in os.walk('quantbase_trading_data'):\n                for file in files:\n                    if any(keyword in file for keyword in ['MASTER_', 'FUTURE_', 'CONFIG_']):\n                        file_path = os.path.join(root, file)\n                        arcname = os.path.relpath(file_path, '.')\n                        zipf.write(file_path, arcname)\n                        essential_files.append(file)\n        \n        # Performance analysis\n        if os.path.exists('quantbase_trading_data/analysis'):\n            for file in os.listdir('quantbase_trading_data/analysis'):\n                file_path = f\"quantbase_trading_data/analysis/{file}\"\n                zipf.write(file_path, f\"analysis/{file}\")\n                essential_files.append(file)\n        \n        # Add a README for this ZIP (fixed string formatting)\n        readme_essential = f\"\"\"QuantBase ESSENTIAL Files Package\nGenerated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\nCrypto: {TRAINING_CRYPTO} ({crypto_name})\n\nüî• THIS IS THE MOST IMPORTANT PACKAGE FOR YOUR TRADING BOT!\n\nFiles included:\n{chr(10).join(f'- {file}' for file in essential_files)}\n\nQuick Start:\n1. Extract this ZIP\n2. Use MASTER_{crypto_suffix}_trading_data.csv in your trading bot\n3. Column 'ensemble_prediction' = price prediction  \n4. Column 'ensemble_signal' = BUY/SELL/HOLD\n\nIntegration code:\n```python\nimport pandas as pd\ndf = pd.read_csv('MASTER_{crypto_suffix}_trading_data.csv')\nlatest = df.iloc[-1]\nprint(f\"Price prediction: ${{latest['ensemble_prediction']:.2f}}\")\nprint(f\"Trading signal: {{latest['ensemble_signal']}}\")\n```\n\n‚≠ê Download the MODELS package next for complete setup!\n\"\"\"\n        zipf.writestr('README_ESSENTIAL.txt', readme_essential)\n    \n    zip_files_created.append(('ESSENTIAL', essential_zip, len(essential_files)))\n    print(f\"   ‚úÖ {essential_zip} ({len(essential_files)} files)\")\n    \n    # 2. MODELS ZIP (Trained ML Models)\n    print(\"\\nüì¶ 2. Creating MODELS ZIP...\")\n    models_zip = f\"QuantBase_MODELS_{crypto_suffix}_{timestamp}.zip\"\n    \n    model_files = []\n    if os.path.exists('quantbase_models'):\n        with zipfile.ZipFile(models_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n            for file in os.listdir('quantbase_models'):\n                if file.endswith('.pkl'):\n                    file_path = f\"quantbase_models/{file}\"\n                    zipf.write(file_path, f\"models/{file}\")\n                    model_files.append(file)\n            \n            # Add models README (fixed string formatting)\n            readme_models = f\"\"\"QuantBase MODELS Package  \nGenerated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\nCrypto: {TRAINING_CRYPTO} ({crypto_name})\n\nü§ñ Trained ML Models (8 algorithms):\n\nFiles included:\n{chr(10).join(f'- {file}' for file in model_files)}\n\nModel Types:\n- LightGBM: Fast, accurate gradient boosting\n- XGBoost: Extreme gradient boosting\n- RandomForest: Ensemble tree method\n- ExponentialSmoothing: Statistical baseline\n- NBEATS: Deep learning for time series\n- LSTM: Neural network for sequences\n- TiDE: Transformer model\n- TFT: Temporal Fusion Transformer\n\nUsage:\n```python\nfrom darts.models import LightGBMModel\nmodel = LightGBMModel.load('models/lightgbm_model.pkl')\nprediction = model.predict(n=7)  # 7-day forecast\nprint(f\"7-day forecast: ${{prediction.values()[-1][0]:.2f}}\")\n```\n\n‚ö†Ô∏è Requires 'darts' library: pip install darts[all]\n\"\"\"\n            zipf.writestr('README_MODELS.txt', readme_models)\n        \n        zip_files_created.append(('MODELS', models_zip, len(model_files)))\n        print(f\"   ‚úÖ {models_zip} ({len(model_files)} files)\")\n    else:\n        print(\"   ‚ö†Ô∏è  No models directory found\")\n    \n    # 3. RESULTS ZIP (Analysis & Visualizations)\n    print(\"\\nüì¶ 3. Creating RESULTS ZIP...\")\n    results_zip = f\"QuantBase_RESULTS_{crypto_suffix}_{timestamp}.zip\"\n    \n    result_files = []\n    with zipfile.ZipFile(results_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        # Results from quantbase_results\n        if os.path.exists('quantbase_results'):\n            for file in os.listdir('quantbase_results'):\n                file_path = f\"quantbase_results/{file}\"\n                zipf.write(file_path, f\"results/{file}\")\n                result_files.append(file)\n        \n        # Individual prediction files (smaller CSV files)\n        if os.path.exists('quantbase_trading_data/predictions'):\n            for file in os.listdir('quantbase_trading_data/predictions'):\n                if file.endswith('_predictions.csv'):  # Individual model predictions\n                    file_path = f\"quantbase_trading_data/predictions/{file}\"\n                    zipf.write(file_path, f\"individual_predictions/{file}\")\n                    result_files.append(file)\n        \n        # Add results README\n        readme_results = f\"\"\"QuantBase RESULTS Package\nGenerated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\nCrypto: {TRAINING_CRYPTO} ({crypto_name})\n\nüìä Analysis Results & Visualizations:\n\nFiles included:\n{chr(10).join(f'- {file}' for file in result_files)}\n\nContents:\n- model_evaluation.csv: Performance comparison\n- predictions_*.png: Visualization plots  \n- processed_data.csv: Cleaned training data\n- Individual model prediction CSVs\n\nUse for:\n- Performance analysis\n- Model comparison\n- Visualization in presentations\n- Detailed backtesting\n\"\"\"\n        zipf.writestr('README_RESULTS.txt', readme_results)\n    \n    zip_files_created.append(('RESULTS', results_zip, len(result_files)))\n    print(f\"   ‚úÖ {results_zip} ({len(result_files)} files)\")\n    \n    # 4. DOCUMENTATION ZIP\n    print(\"\\nüì¶ 4. Creating DOCUMENTATION ZIP...\")\n    docs_zip = f\"QuantBase_DOCS_{crypto_suffix}_{timestamp}.zip\"\n    \n    with zipfile.ZipFile(docs_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        # Create comprehensive documentation (fixed string formatting)\n        \n        # Main README\n        main_readme = f\"\"\"# QuantBase ML Package - Complete Documentation\n\n## üöÄ Quick Start Guide\n\n### For Trading Bot Integration (PRIORITY)\n1. **Download & Extract**: QuantBase_ESSENTIAL_*.zip  \n2. **Main File**: MASTER_{crypto_suffix}_trading_data.csv\n3. **Integration**: See trading_bot_integration.md\n\n### For ML Development  \n1. **Download**: QuantBase_MODELS_*.zip\n2. **Load Models**: See model_usage_guide.md\n3. **Retrain**: Use the Colab notebook\n\n## üìä Training Results Summary\n\n**Cryptocurrency**: {TRAINING_CRYPTO} ({crypto_name})\n**Current Price**: ${crypto_data['Close'].iloc[-1]:.2f}\n**Training Period**: {crypto_data.index.min().strftime('%Y-%m-%d')} to {crypto_data.index.max().strftime('%Y-%m-%d')}\n**Data Points**: {len(crypto_data):,}\n**Models Trained**: 8 (LightGBM, XGBoost, LSTM, etc.)\n\n## üìÅ Package Structure\n\n```\nQuantBase_ESSENTIAL_*.zip     üî• DOWNLOAD FIRST\n‚îú‚îÄ‚îÄ MASTER_*_trading_data.csv     (Main trading file)\n‚îú‚îÄ‚îÄ FUTURE_*_7day_forecasts.csv   (Price predictions)  \n‚îú‚îÄ‚îÄ TRADING_BOT_CONFIG_*.csv       (Bot configuration)\n‚îî‚îÄ‚îÄ analysis/model_performance_*.csv\n\nQuantBase_MODELS_*.zip        ü§ñ ML Models\n‚îú‚îÄ‚îÄ models/lightgbm_model.pkl\n‚îú‚îÄ‚îÄ models/xgboost_model.pkl\n‚îî‚îÄ‚îÄ ... (8 total models)\n\nQuantBase_RESULTS_*.zip       üìä Analysis & Plots  \n‚îú‚îÄ‚îÄ results/model_evaluation.csv\n‚îú‚îÄ‚îÄ results/predictions_*.png\n‚îî‚îÄ‚îÄ individual_predictions/\n\nQuantBase_DOCS_*.zip          üìö This Documentation\n```\n\n## üéØ Integration Priority\n\n### Phase 1: Basic Integration (5 minutes)\n```python\nimport pandas as pd\n\n# Load main trading data\ndf = pd.read_csv('MASTER_{crypto_suffix}_trading_data.csv')\nlatest = df.iloc[-1]\n\nprediction = latest['ensemble_prediction']\nsignal = latest['ensemble_signal']\nconfidence = 100 - abs(latest['ensemble_error_pct'])\n\nprint(f\"SOL Price Prediction: ${{prediction:.2f}}\")\nprint(f\"Trading Signal: {{signal}}\")\nprint(f\"Confidence: {{confidence:.1f}}%\")\n```\n\n### Phase 2: Advanced Integration (30 minutes)\n- Load individual models for custom ensembles\n- Implement real-time prediction updates  \n- Add risk management and position sizing\n- See trading_bot_integration.md for details\n\n## üèÜ Model Performance Preview\n\nBest performing models (by accuracy):\n1. **LightGBM**: Fast, reliable, good baseline\n2. **XGBoost**: Excellent for financial data\n3. **LSTM**: Captures complex patterns\n4. **Ensemble**: Average of all models (recommended)\n\n## üîß Technical Requirements\n\n**For Trading Bot**:\n- Python 3.8+\n- pandas, numpy\n- Files from ESSENTIAL package\n\n**For ML Development**:  \n- darts[all] library\n- PyTorch (for deep learning models)\n- Files from MODELS package\n\n## üÜò Support & Troubleshooting\n\n**Common Issues**:\n- Model loading errors ‚Üí Install darts[all]\n- CSV parsing errors ‚Üí Check file paths\n- Prediction errors ‚Üí Verify data format\n\n**Team Roles**:\n- **Trading Bot Dev**: Use ESSENTIAL package\n- **ML Engineer**: Use MODELS + RESULTS packages  \n- **Frontend Dev**: Use RESULTS for visualizations\n- **Backend Dev**: Use ESSENTIAL for API endpoints\n\nCreated with ‚ù§Ô∏è for QuantBase hackathon team!\nGPU-trained on Google Colab for maximum performance.\n\"\"\"\n        zipf.writestr('README.md', main_readme)\n        \n        # Trading bot integration guide\n        bot_guide = f\"\"\"# Trading Bot Integration Guide\n\n## üéØ Quick Integration (5 minutes)\n\n### Step 1: Load Prediction Data\n```python\nimport pandas as pd\n\ndef get_prediction():\n    df = pd.read_csv('MASTER_{crypto_suffix}_trading_data.csv')\n    return df.iloc[-1]  # Latest prediction\n\nlatest = get_prediction()\nprice = latest['ensemble_prediction']\nsignal = latest['ensemble_signal']\n```\n\n### Step 2: Basic Trading Logic\n```python\ndef should_trade(prediction_row):\n    price_pred = prediction_row['ensemble_prediction']\n    current_price = prediction_row['actual_price']\n    signal = prediction_row['ensemble_signal']\n    \n    # Calculate expected return\n    expected_return = (price_pred - current_price) / current_price * 100\n    \n    if signal == 'BUY' and expected_return > 1.0:\n        return 'BUY'\n    elif signal == 'SELL' and expected_return < -1.0:\n        return 'SELL'\n    else:\n        return 'HOLD'\n```\n\n### Step 3: API Endpoint (Flask)\n```python\nfrom flask import Flask, jsonify\n\napp = Flask(__name__)\n\n@app.route('/prediction')\ndef get_prediction_api():\n    latest = get_prediction()\n    return jsonify({{\n        'crypto': '{TRAINING_CRYPTO}',\n        'predicted_price': float(latest['ensemble_prediction']),\n        'signal': str(latest['ensemble_signal']),\n        'confidence': max(0, 100 - abs(latest['ensemble_error_pct'])),\n        'timestamp': str(latest['timestamp'])\n    }})\n```\n\n## üìä Data Files Reference\n\n### MASTER_{crypto_suffix}_trading_data.csv\n**Main trading file - USE THIS!**\n\nKey columns:\n- `ensemble_prediction`: Predicted price (average of 8 models)\n- `ensemble_signal`: BUY/SELL/HOLD recommendation\n- `ensemble_error_pct`: Historical accuracy\n- `timestamp`: Prediction date\n- `actual_price`: Historical actual price\n\n### FUTURE_{crypto_suffix}_7day_forecasts.csv  \n**7-day ahead predictions**\n\nColumns:\n- All model predictions for next 7 days\n- `ensemble_forecast`: Average prediction (recommended)\n- Date index for each forecast day\n\n### TRADING_BOT_CONFIG_{crypto_suffix}.csv\n**Bot configuration settings**\n\nContains:\n- Best performing model name\n- Current price ranges\n- Training metadata\n- File paths\n\n## üöÄ Production Deployment\n\n### Real-time Updates\n```python\nimport schedule\nimport time\n\ndef update_predictions():\n    # Your model retraining logic here\n    # Or fetch new predictions from API\n    pass\n\n# Update predictions daily\nschedule.every().day.at(\"00:00\").do(update_predictions)\n\nwhile True:\n    schedule.run_pending()\n    time.sleep(3600)  # Check every hour\n```\n\n### Risk Management\n```python\ndef calculate_position_size(prediction, portfolio_value, max_risk=0.02):\n    confidence = 100 - abs(prediction['ensemble_error_pct'])\n    expected_return = prediction['ensemble_prediction'] / prediction['actual_price'] - 1\n    \n    # Adjust position size based on confidence and expected return\n    position_size = portfolio_value * max_risk * (confidence / 100) * abs(expected_return)\n    return min(position_size, portfolio_value * 0.1)  # Max 10% per trade\n```\n\nReady for production! üöÄ\n\"\"\"\n        zipf.writestr('trading_bot_integration.md', bot_guide)\n        \n        # Model usage guide  \n        model_guide = f\"\"\"# Model Usage Guide\n\n## ü§ñ Loading Individual Models\n\n```python\nfrom darts.models import LightGBMModel, XGBModel, RNNModel\n\n# Load best performing models\nlightgbm = LightGBMModel.load('models/lightgbm_model.pkl')\nxgboost = XGBModel.load('models/xgboost_model.pkl')\nlstm = RNNModel.load('models/lstm_model.pkl')\n```\n\n## üîÆ Making Predictions\n\n```python\nimport pandas as pd\nfrom darts import TimeSeries\n\n# Load your current price data\ndata = pd.read_csv('your_current_data.csv')\nts = TimeSeries.from_dataframe(data, value_cols=['Close'])\n\n# Make 7-day prediction\nforecast = lightgbm.predict(n=7, series=ts)\nprint(f\"7-day forecast: ${{forecast.values()[-1][0]:.2f}}\")\n```\n\n## üéØ Custom Ensemble\n\n```python\ndef create_custom_ensemble(models, data, weights=None):\n    predictions = []\n    \n    for model in models:\n        pred = model.predict(n=7, series=data)\n        predictions.append(pred.values().flatten())\n    \n    if weights is None:\n        weights = [1/len(models)] * len(models)  # Equal weights\n    \n    ensemble = np.average(predictions, axis=0, weights=weights)\n    return ensemble\n\n# Example: Weight models by performance  \nmodels = [lightgbm, xgboost, lstm]\nweights = [0.4, 0.35, 0.25]  # Based on accuracy\nensemble_pred = create_custom_ensemble(models, current_data, weights)\n```\n\n## üìä Model Performance\n\nBased on training results:\n\n1. **LightGBM**: Fastest, most reliable\n   - Best for: Real-time predictions\n   - Accuracy: High\n   - Speed: Very Fast\n\n2. **XGBoost**: Best for financial data\n   - Best for: Complex patterns\n   - Accuracy: Very High  \n   - Speed: Fast\n\n3. **LSTM**: Deep learning\n   - Best for: Long-term trends\n   - Accuracy: High\n   - Speed: Medium\n\nUse ensemble of top 3 models for best results!\n\"\"\"\n        zipf.writestr('model_usage_guide.md', model_guide)\n    \n    zip_files_created.append(('DOCS', docs_zip, 4))\n    print(f\"   ‚úÖ {docs_zip} (4 documentation files)\")\n    \n    return zip_files_created\n\n# Create the ZIP files\nzip_files = create_small_zip_chunks()\n\n# Display download instructions\nprint(f\"\\nüéâ SUCCESS! Created {len(zip_files)} downloadable ZIP files\")\nprint(\"=\"*70)\nprint(\"üì• DOWNLOAD ORDER (Click each in Colab file browser):\")\nprint()\n\nfor i, (category, filename, file_count) in enumerate(zip_files, 1):\n    file_size = os.path.getsize(filename) / (1024*1024)  # Size in MB\n    \n    if category == 'ESSENTIAL':\n        print(f\"üî• {i}. {filename}\")\n        print(f\"   üìä {file_count} files, {file_size:.1f} MB\")\n        print(f\"   ‚≠ê DOWNLOAD THIS FIRST - Contains main trading data!\")\n        \n    elif category == 'MODELS':\n        print(f\"ü§ñ {i}. {filename}\")\n        print(f\"   üì¶ {file_count} files, {file_size:.1f} MB\")\n        print(f\"   üí° For ML development and custom models\")\n        \n    elif category == 'RESULTS':\n        print(f\"üìä {i}. {filename}\")\n        print(f\"   üìà {file_count} files, {file_size:.1f} MB\")  \n        print(f\"   üìã For analysis and visualizations\")\n        \n    elif category == 'DOCS':\n        print(f\"üìö {i}. {filename}\")\n        print(f\"   üìÑ {file_count} files, {file_size:.1f} MB\")\n        print(f\"   üìñ Complete documentation and guides\")\n    \n    print()\n\nprint(\"üöÄ HACKATHON QUICK START:\")\nprint(\"1. Download QuantBase_ESSENTIAL_*.zip first\")\nprint(\"2. Extract and use MASTER_*.csv in your trading bot\")\nprint(\"3. Download other ZIPs as needed\")\nprint(\"4. See README files in each ZIP for instructions\")\n\nprint(f\"\\nüí∞ Ready for {crypto_name} trading bot integration!\")\nprint(\"Perfect for your hackathon demo! üèÜ\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Alternative Download - Individual Files (If ZIP Download Fails)\nprint(\"üì• Alternative Download Method - Individual Files\")\nprint(\"=\"*60)\n\n# If the ZIP download failed, use this cell to download files individually\nimport os\nfrom IPython.display import display, HTML\n\ndef create_download_links():\n    \"\"\"Create individual download links for all important files\"\"\"\n    \n    print(\"üîó Individual Download Links:\")\n    print(\"Click each link to download files one by one\")\n    print()\n    \n    # Important files to download\n    download_files = []\n    \n    # 1. Model files\n    if os.path.exists('quantbase_models'):\n        print(\"ü§ñ Model Files:\")\n        for file in os.listdir('quantbase_models'):\n            if file.endswith('.pkl'):\n                file_path = f'quantbase_models/{file}'\n                download_files.append(('Model', file, file_path))\n                print(f\"   üìÑ {file}\")\n    \n    # 2. Trading data files  \n    if os.path.exists('quantbase_trading_data'):\n        print(\"\\nüìä Trading Data Files:\")\n        \n        # Master trading file (most important)\n        for root, dirs, files in os.walk('quantbase_trading_data'):\n            for file in files:\n                if 'MASTER_' in file or 'FUTURE_' in file or 'CONFIG_' in file:\n                    file_path = os.path.join(root, file)\n                    download_files.append(('Trading Data', file, file_path))\n                    print(f\"   üìÑ {file}\")\n        \n        # Performance analysis\n        if os.path.exists('quantbase_trading_data/analysis'):\n            for file in os.listdir('quantbase_trading_data/analysis'):\n                file_path = f'quantbase_trading_data/analysis/{file}'\n                download_files.append(('Analysis', file, file_path))\n                print(f\"   üìÑ {file}\")\n    \n    # 3. Results and visualizations\n    if os.path.exists('quantbase_results'):\n        print(\"\\nüìà Results Files:\")\n        for file in os.listdir('quantbase_results'):\n            file_path = f'quantbase_results/{file}'\n            download_files.append(('Results', file, file_path))\n            print(f\"   üìÑ {file}\")\n    \n    return download_files\n\n# Create download links\ndownload_files = create_download_links()\n\nprint(f\"\\nüìã Total files to download: {len(download_files)}\")\nprint(\"\\nüí° Download Instructions:\")\nprint(\"1. Right-click on each file in the Colab file browser (left sidebar)\")\nprint(\"2. Select 'Download'\")\nprint(\"3. Organize files according to COLAB_DOWNLOAD_GUIDE.md\")\n\n# Priority download order\nprint(\"\\nüéØ PRIORITY DOWNLOAD ORDER:\")\nprint(\"=\"*40)\n\npriority_files = [\n    \"MASTER_SOL_USD_trading_data.csv\",\n    \"TRADING_BOT_CONFIG_SOL_USD.csv\", \n    \"FUTURE_SOL_USD_7day_forecasts.csv\",\n    \"model_performance_SOL_USD.csv\",\n    \"lightgbm_model.pkl\",\n    \"xgboost_model.pkl\"\n]\n\nprint(\"üî• Essential files (download these first):\")\nfor i, filename in enumerate(priority_files, 1):\n    for category, file, path in download_files:\n        if filename in file:\n            print(f\"   {i}. {file} ({category})\")\n            break\n\nprint(\"\\nüìÅ File browser locations:\")\nprint(\"   ü§ñ Models: quantbase_models/\")\nprint(\"   üìä Trading Data: quantbase_trading_data/predictions/\")\nprint(\"   üìà Analysis: quantbase_trading_data/analysis/\")\nprint(\"   üìã Config: quantbase_trading_data/\")\nprint(\"   üìä Results: quantbase_results/\")\n\n# Create a simple text file with file listing\nfile_list = f\"\"\"QuantBase ML Files Download List\nGenerated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\nCrypto: {TRAINING_CRYPTO} ({crypto_name})\n\nPRIORITY FILES (Download First):\n\"\"\"\n\nfor i, filename in enumerate(priority_files, 1):\n    for category, file, path in download_files:\n        if filename in file:\n            file_list += f\"{i}. {file} -> {path}\\n\"\n            break\n\nfile_list += f\"\"\"\n\nALL FILES:\n\"\"\"\n\nfor category, file, path in download_files:\n    file_list += f\"{category}: {file} -> {path}\\n\"\n\nfile_list += f\"\"\"\n\nFOLDER STRUCTURE FOR YOUR REPO:\nproject-steve/ml_models/\n‚îú‚îÄ‚îÄ models/          <- Put .pkl files here\n‚îú‚îÄ‚îÄ data/\n‚îÇ   ‚îú‚îÄ‚îÄ predictions/ <- Put MASTER_*.csv, FUTURE_*.csv here  \n‚îÇ   ‚îú‚îÄ‚îÄ analysis/    <- Put model_performance_*.csv here\n‚îÇ   ‚îî‚îÄ‚îÄ config/      <- Put TRADING_BOT_CONFIG_*.csv here\n‚îî‚îÄ‚îÄ results/         <- Put evaluation results here\n\nINTEGRATION QUICK START:\n1. Download MASTER_SOL_USD_trading_data.csv\n2. Use this file in your trading bot\n3. Column 'ensemble_prediction' = price prediction\n4. Column 'ensemble_signal' = BUY/SELL/HOLD signal\n\"\"\"\n\n# Save file list\nwith open('DOWNLOAD_FILE_LIST.txt', 'w') as f:\n    f.write(file_list)\n\nprint(\"\\n‚úÖ Created DOWNLOAD_FILE_LIST.txt\")\nprint(\"   This file contains all download paths and instructions\")\nprint(\"   Download this file first for reference!\")\n\nprint(f\"\\nüéØ SUMMARY FOR HACKATHON:\")\nprint(\"=\"*50)\nprint(f\"Crypto trained: {crypto_name} (SOL-USD)\")\nprint(f\"Models available: {len([f for f in download_files if f[0] == 'Model'])}\")\nprint(f\"Trading files: {len([f for f in download_files if f[0] == 'Trading Data'])}\")\nprint(\"Ready for bot integration! üöÄ\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "5946949b14e74cd8bdfd737a0a8a0232": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a6b1179cba81406f8660b8301ac52c7b",
       "IPY_MODEL_b425482748a94482be635b2b56178558",
       "IPY_MODEL_073063db156c4f199d47cf4651d932e0"
      ],
      "layout": "IPY_MODEL_6c2bffef219840cdba4b9c2fff3009ac"
     }
    },
    "a6b1179cba81406f8660b8301ac52c7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_56aef32d5165416ea0055135835da42a",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_cc1d4960b61e4c028307db9dc61f0565",
      "value": "Epoch‚Äá5:‚Äá‚Äá‚Äá0%"
     }
    },
    "b425482748a94482be635b2b56178558": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_baf8e80733674fc0ba55367319e6f8f3",
      "max": 12,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_22777311f956401ebd759c24d384adf8",
      "value": 0
     }
    },
    "073063db156c4f199d47cf4651d932e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_74fa2ef9bc254f80b55d72d8b878345d",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_f1f49078f0024cfaa7a1717a6b97bd75",
      "value": "‚Äá0/12‚Äá[00:00&lt;?,‚Äá?it/s,‚Äátrain_loss=3.47e+7]"
     }
    },
    "6c2bffef219840cdba4b9c2fff3009ac": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "56aef32d5165416ea0055135835da42a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc1d4960b61e4c028307db9dc61f0565": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "baf8e80733674fc0ba55367319e6f8f3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "22777311f956401ebd759c24d384adf8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "74fa2ef9bc254f80b55d72d8b878345d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f1f49078f0024cfaa7a1717a6b97bd75": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0c2c103c5c99409cba4b2b89a54bf3b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_667652dc809f4a2e93466819fe00d5b0",
       "IPY_MODEL_d9ab961094d8427abc48293023197bb2",
       "IPY_MODEL_1615e66237d34748a987d5d74beb9cd7"
      ],
      "layout": "IPY_MODEL_46838263b89d4490baabc4c7cbe682f2"
     }
    },
    "667652dc809f4a2e93466819fe00d5b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_556895edeb62443791713bb04783f4d3",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_6a4efd7aba8f4027ad56915a3e041e3b",
      "value": "Epoch‚Äá11:‚Äá100%"
     }
    },
    "d9ab961094d8427abc48293023197bb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d362a943865e496e89b0cda8a82d7d32",
      "max": 24,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d351acc541994b90bb977a442a90f69c",
      "value": 24
     }
    },
    "1615e66237d34748a987d5d74beb9cd7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8cc13958d11e4557971101379d5ac4f8",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_ed90be05f8ed4c60b48b2433e318e9df",
      "value": "‚Äá24/24‚Äá[00:02&lt;00:00,‚Äá‚Äá9.44it/s,‚Äátrain_loss=4.78e+5]"
     }
    },
    "46838263b89d4490baabc4c7cbe682f2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "556895edeb62443791713bb04783f4d3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a4efd7aba8f4027ad56915a3e041e3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d362a943865e496e89b0cda8a82d7d32": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d351acc541994b90bb977a442a90f69c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8cc13958d11e4557971101379d5ac4f8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed90be05f8ed4c60b48b2433e318e9df": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3445e36403184c4daee77379e9946350": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_22ddfa8f380a442186375367710a1b24",
       "IPY_MODEL_bc0d3af2ba564869848a3b356495cf85",
       "IPY_MODEL_fba0460fed9a46c5aff7aaf6f343adf4"
      ],
      "layout": "IPY_MODEL_ac72bd63c9f94209b7a6b3acf0fe9b98"
     }
    },
    "22ddfa8f380a442186375367710a1b24": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6cd4a1e53359468caa89c65b70307d05",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_c90bc4ddd95b48b4aec2e54b86e20ec1",
      "value": "Predicting‚ÄáDataLoader‚Äá0:‚Äá100%"
     }
    },
    "bc0d3af2ba564869848a3b356495cf85": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c60034acdd20465998f6dfd182270dc1",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_233b225a26934a4fb069aa57e916cad6",
      "value": 1
     }
    },
    "fba0460fed9a46c5aff7aaf6f343adf4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7307c0ba5bf2436e858fe97f3b8a2342",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_658f1ffa4fdb457c826161e2d9409f66",
      "value": "‚Äá1/1‚Äá[00:00&lt;00:00,‚Äá14.18it/s]"
     }
    },
    "ac72bd63c9f94209b7a6b3acf0fe9b98": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "6cd4a1e53359468caa89c65b70307d05": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c90bc4ddd95b48b4aec2e54b86e20ec1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c60034acdd20465998f6dfd182270dc1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "233b225a26934a4fb069aa57e916cad6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7307c0ba5bf2436e858fe97f3b8a2342": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "658f1ffa4fdb457c826161e2d9409f66": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "27e4a142bc5948dfad67c2d12cac4cb4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cd9d732d8ed0443f9a860820053f03b6",
       "IPY_MODEL_88f8387b62ba4937801292e171e8a90b",
       "IPY_MODEL_a5ec82af667a4b0fb5d13047acf1119a"
      ],
      "layout": "IPY_MODEL_8506740c4e154365b82a2faf203596c6"
     }
    },
    "cd9d732d8ed0443f9a860820053f03b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0ea10846cb94375836f242a512cc4a4",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_f669ee2387ef482b97aaf483f5e6e082",
      "value": "Predicting‚ÄáDataLoader‚Äá0:‚Äá100%"
     }
    },
    "88f8387b62ba4937801292e171e8a90b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_245483d83c1d4d3f897b6260db218482",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_708aff0db6e7453ca4857fceffd66d3b",
      "value": 1
     }
    },
    "a5ec82af667a4b0fb5d13047acf1119a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_10f8fda185d14e91a43c552da05b9c99",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_13686687430f4741b9600aafbfbbc5e5",
      "value": "‚Äá1/1‚Äá[00:00&lt;00:00,‚Äá25.13it/s]"
     }
    },
    "8506740c4e154365b82a2faf203596c6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "a0ea10846cb94375836f242a512cc4a4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f669ee2387ef482b97aaf483f5e6e082": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "245483d83c1d4d3f897b6260db218482": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "708aff0db6e7453ca4857fceffd66d3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "10f8fda185d14e91a43c552da05b9c99": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "13686687430f4741b9600aafbfbbc5e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}